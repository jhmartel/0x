{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONWY2R/j6DWS6+r52ioz+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhmartel/fp/blob/master/_notebooks/2022-10-19-Colloquium_MRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colloquium. Welcome to Optimal Transport \n",
        "\n",
        "> \"Welcome to the basic ideas of optimal transport. From Monge to Kantorovich.\" \n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: JHM\n",
        "- categories: [fastpages, jupyter]"
      ],
      "metadata": {
        "id": "dZjFoMvcf7Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# _Colloquium Talk: Welcome to Optimal Transport_\n",
        "\n",
        "Here is the rough content of our presentation October 18, 2022 at MRU. EA 1026. \n",
        "\n",
        "Optimal Transport starts with question: how to get from $x$ to $y$? Or specifically, how to get unit mass $\\delta_x$ from a productive source to a unit mass $\\delta_y$ at consumption target? Here is instance where we have too many choices! So we begin to consider Hamiltonian Principle, and looking for ground states of energies, or, cost minimizers. \n",
        "\n",
        "To motivate transport between Borel-Radon measures. We did not emphasize the continuity and stability of OT like we wanted to. But Borel-Radon measures and weak_$*$ convergence and the continuity properties are very important for applications to topology. So we imagine a distribution $\\sigma$ of productive sources and a given target $\\tau$ of consumptive targets, and the question we are asking is \"_How to get from $\\sigma$ to $\\tau$?_\"\n",
        "\n",
        "Now as we'll describe the OT program requires a choice of $\\sigma$, $\\tau$, and a choice of cost $c: X\\times Y \\to {\\bf{R}} \\cup\\{ +\\infty\\}$.\n",
        "\n",
        "\n",
        "# _Monge, Deblais et Reblais_\n",
        "Let's go through history and start with Monge [(1761)] where he's literally moving volumes of earth for Napoleon. The Monge Problem is $$(MP) : ~~ \\inf_{T} \\int ||x- T(x)||d\\sigma(x)$$ where the infimum is over all maps $T: {\\bf{R}}^n \\to {\\bf{R}}^n$ satisfying $T\\#\\sigma = \\tau$ (if any such maps exist at all!) Given some basic regularity on $T$, i.e. Lipschitz, then we can infer the Monge-Ampere equation $$det(DT(x)) = \\frac{g(T(x))}{f(x)}$$ but this equation is effectively useuless in practice.\n",
        "\n",
        "Okay, so our point is this: that Monge started with a very difficult problem, namely with the unfortunate cost $c(x,y)=d^1(x,y) = ||x-y||$. The fact that this cost is __not__ strictly convex __is__ problematic in practice. Moreover the fact that $x\\mapsto ||x||$ is not differentiable at $x=0$ is also extremely problematic in practice. In otherwords, the $L^1$ norm is a very difficult choice of cost, especially to begin with. As we will explain below, in a certain sense the most canonical cost is actually the quadratic cost $c(x,y)=d^2(x,y)/2 = ||x-y||^2/2$. \n",
        "\n",
        "# _Kantorovich's Linearization_\n",
        "After Monge, we next consider Leonid Kantorovich, and this is big jump in history. We say that Kantorovich basically _linearized_ the whole problem, replacing the rather intractable space of maps $T: X \\to Y$ with the space of Borel-Radon measures $\\pi$ on the product $X\\times Y$, and the pushforward condition $T\\# \\sigma = \\tau$ being replaced with two constraints $$pr_X \\# \\pi \\leq \\sigma, ~~~ pr_Y \\# \\pi =\\tau.$$ Here $pr_X$ and $pr_Y$ are the canonical projections from $X\\times Y$ to $X,Y$, respectively. Let $SC(\\sigma, \\tau)$ represent this set of semicoupling measures from the source $\\sigma$ to target $\\tau$. The important point is that $SC(\\sigma, \\tau)$ is a nonempty, convex, weak-$*$ compact subset of Borel-Radon measures on $X\\times Y$. \n",
        "\n",
        "Next Kantorovich observes that for continuous costs $c: X\\times Y \\to {\\bf{R}} \\cup \\{+\\infty\\}$ we obtain continuous linear functionals on $SC$ defined by $$\\pi \\mapsto \\int c(x,y) ~d\\pi(x,y).$$ \n",
        "So for every choice of source, target, and cost, we find the Monge-Kantorovich program: $$(MK): ~~~ \\min_{\\pi\\in SC(\\sigma, \\tau)} \\int c(x,y) ~ d\\pi(x,y).$$ From this program we see that indeed the minimum _is_ attained, being a linear function on a convex compact set. \n",
        "\n",
        "At this stage we would like to focus on _finitely supported_ source and targets, namely $$\\sigma = \\delta_{x_1} +\\cdots+\\delta_{x_n}$$ and $$\\tau = \\delta_{y_1} +\\cdots+\\delta_{y_n}.$$\n",
        "\n",
        "Then the set of measure-preserving mappings from $\\sigma$ to $\\tau$ corresponds to bijective maps from the n-element sets, i.e. basically corresponding to a permutation from $X$ to $Y$. However Kantorovich introduces the set of bistochastic $n\\times n$ bistochastic matrices $$BS(n) = \\{(a_{ij}) \\} $$ where $a_{ij}$ satisfes $$ a_{ij} \\geq 0,~~~ \\sum_i a_{ij} = 1 = \\sum_j a_{ij}~~ $$ for every choice fo indexes $i,j$. In otherwords all the couplings from $X$ to $Y$ corresponds to an invertible stochastic transformation, where the sum of every column and the sum of every row is equal to unity. \n",
        "\n",
        "The key point about $BS(n)$ is the so-called Choquet-Birkhoff-von Neumman theorem that the set of extreme points of $BS(n)$ is exactly the $n!$ set of permutation matrices $extreme(BS(n)) \\approx Sym_n$. This means every linear functional on $BS(n)$ is minimized at a permutation matrix, i.e. represented by a bijection map $X \\to Y$. Equivalently the optimal coupling will not \"split\" any mass. The above remarks are intended to give some idea of the structure of the set of semicouplings $SC$. It's somehow accessible. \n",
        "\n",
        "So again the Monge perspective is to minimize over the bijection maps $T: X\\to Y$, i.e. permutations $T: \\underline{n} \\to \\underline{n}$. The linearized Kantorovich perspective to study the convex set $BS(n)$ which consists of multivalued type maps between $\\underline{n}$ and $\\underline{n}$. Then we seek to minimize a linear function over a convex set (as opposed to minimizing over the discrete set of extreme points).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EWYQfKOp2Oyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# _Kantorovich's Dual Max Program_\n",
        "\n",
        "The next step is to introduce Kantorovich's dual max program. How can we motivate this amazing step? Abruptly we can just introduce the transporters point of view, which consists of setting prices $-\\phi(x)$ on the source $x\\in X$, and prices $\\psi(y)$ on the target $y\\in Y$. The prices are competitive if and only if they satisfy the important inequality $$-\\phi(x) + \\psi(y) \\leq c(x,y)$$ pointwise for all $x\\in X$, $y\\in Y$. The Kantorovich program looks to maximize the surplus over all pairs of potentials $\\phi, \\psi$ on $X, Y$, respectively. Specifically: $$(MAX)~:~~\\sup_{\\phi, \\psi~} \\left( -\\int \\phi(x)d\\sigma(x) + \\int \\psi(y) d\\tau(y) \\right),$$ where the supremum is taken over all potentials satisfying the above inequality $-\\phi+\\psi \\leq c$. This inequality implies immediately that (MAX) is less than or equal to (MK), i.e. $$(MAX) \\leq (MK).$$ However the amazing fact underlying optimal transportation is that the max equals the min, and there is _no duality gap_. This implies that $c$-optimal semicouplings are supported on the set where equality is attained $$-\\phi(x)+\\psi(y) \\leq c(x,y)$$ with _equality_ if and only if $(x,y)\\in spt(\\pi)$. This motivates the definition of $c$-subdifferentials $\\partial^c \\phi(x)$. "
      ],
      "metadata": {
        "id": "LU5fzxHPXUMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# _(Twist) Condition and Uniqueness_\n",
        "\n",
        "# _Basic Regularity_\n",
        "\n",
        "# _Topics Briefly Touched On:_\n",
        "- Kantorovich's dual program enables a dimension reduction! We don't really need to search out the $dim(X) \\times dim(Y)$ space of semicouplings, but instead the optimal transports are defined by basically $dim(Y)$ parameters, or equivalently $dim(X)$ parameters. \n",
        "\n",
        "- We did not cover McCann's displacement convexity, the qualitative curvature descriptions, that $R_{ij} \\geq 0$ if and only if entropy is concave along displacement interpolations.\n",
        "\n",
        "- The singularity $Z$ and the basic Brouwer No-Retract theorem. We interpret semicouplings from $X$ to $\\partial X$ as basically representing deformation retracts. \n",
        "\n",
        "- We briefly elaborated how $c(x,y)=d^2(x,y)/2=||x-y||^2/2$ is the canonical cost, or equivalently $c(x,y)=\\langle x ,y \\rangle$. However there is no real canonical cost from ${\\bf{R}}^n \\to {\\bf{R}}^k$. \n",
        "\n",
        "- Challenging to construct costs between arbitrary surfaces, e.g. $T^2 \\times S^2 \\to \\bf{R}$ or $S_g \\times S^2 \\to \\bf{R}$ where $S_g$ is a genus $g$ hyperbolic surface. In fact more interesting is constructing costs from $X$ to $AG_0(S^2)$ using the Dold-Thom theorem. \n"
      ],
      "metadata": {
        "id": "JWCISvN3be8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hide\n",
        "\n",
        "# Colloquium Talk: Computational Optimal Transport\n",
        "\n",
        "It is my pleasure to deliver this colloquium to the Dept. of Mathematics and Computing here at MRU, and I will look to address the connections of _computation_ and _optimal transport_ . \n",
        "\n",
        "I hope to give a broad overview of OT as I see it. And it's proper to give a broad view because OT is very general, and it's based fundamentally on Monge-Kantorovich duality, which itself is really a consequence of the Fenchel-Legendre transform on convex functions on $R^n$. So I consider it a fundamental subject that students and everybody should learn.\n",
        "\n",
        "\n",
        "Where to begin? What can be understood by everybody in the audience? \n",
        "\n",
        "1. We have a map [insert image]. Everybody asks how to get from $A$ to $B$. (Start with two points). \n",
        "\n",
        "2. On the map we have 100 source points, this is some unit of physical good. (Pounds of coffee beans, pounds of dirt, fluid, matter). These 100 points could all be concentrated at one physical location, or be randomly sampled from a fixed distribution, or represent free gas particles, etc.. Now given this source distibution $\\sigma$, we might want to relocate it (e.g. for processing, for selling, or disposal, etc.). \n",
        "\n",
        "[Illustrate with pictures]. \n",
        "\n",
        "My presentation: we are given a target distibution $\\tau$ on the space. These could be delivery addresses where a prescribed amount of ``mass\" is required.\n",
        "\n",
        "\n",
        "\n",
        "[Intro: Jacobians, Change of Variables, Integrals]\n",
        "\n",
        "Now I will not address OT through the Monge Ampere equation, although the whole theory is about change of variables, and especially about the pushforwards of measures. (Finding maps with prescribed Jacobians). \n",
        "\n",
        "Recall: if $T : V_1 \\to V_2$ is a linear map, then $vol(T(P))=det(T) vol(P)$ for every parallelipiped $P$. This is interesting and useful result! Because we have an orthonormal frame, or parallelipiped $P$ at $V_1$, and the image $T(P)$ is possibly not orthogonal (i.e. the lengths of the frame can change, and the angles, i.e. there is transvection (unipotent matrices are acting) and non-uniform multiples of the vectors are being added to each other. \n",
        "\n",
        "(Aside: what is the proof? Well ${}^t T T$ is symmetric positive definite, therefore apply spectral theorems and multiplicity of $det({}^t T T) = det(T)^2$. Does this assume too much?). \n",
        "\n",
        "Aside: Oh, and by the way, what is the determinant of a linear transformation ? This is interesting question, because I'm begging for the definition of the determinant. Is the definition the alternating sum over columns, i.e. the recursive computation. Group theoretically, there is a unique Haar measure $\\mu$ on the additive topological vector space ${\\bf{R}}^N$ and this Haar measure is unique up to a constant, i.e. homothety. So if $T$ is a linear map, then $T\\# \\mu$ is another Haar measure, and therefore differs from $\\mu$ by a constant. This constant is the determinant of $T$. And the computation of this determinant is recursively, i.e. by projection. \n",
        "\n",
        "So we have the linear change of variable, and the calculus tells us how to linearize differentiable functions which leads to the integral change of variable formula $$\\int_A  |Jac(DF_x)|~f(x) dx = \\int_{F(A)} f(y) dy$$ if $F$ maps $A$ onto the image $B=F(A)$ diffeomorphically for every open subset $A$ of $X={\\bf{R}}^n$.  \n",
        "\n",
        "So essentially OT is looking to transport measures, namely find measurable maps $T: X \\to Y$ which have given Jacobian constraint, namely $$|Jac(DT_x)| f(x) = g(T(x)) ~~~\\text{pointwise on ~~} X.$$   (Check order of the signs)\n",
        "\n",
        "This is like Monge-Ampere's formulation of the problem. And honestly Monge and Ampere did not make progress on the problem. It's too hard when it's phrased as pure PDE. \n",
        "\n",
        "This is the Monge problem. But Kantorovich [insert full name, picturem, age] was incredible man, and he linearized the problem where instead of looking for differentiable maps $F$ which pushes the source $\\sigma$ onto the target measure $\\tau$, instead we look for measures $\\pi$ whose support represents the graph of a \"function\" (now measurably multivalued) which pushes $\\sigma$ onto $\\tau$. Formally this is defined as the set of semicouplings (in our case).\n",
        "\n",
        "Now to give an idea of what happens (Brenier-McCann-Gangbo): the linearization is very general, and an arbitrary Borel-Radon measure is far from being a map $F$. In otherwords, the category of measurable multivalued maps is way too big. But when we optimize, when we find the measure which globally minimizes the cost (which we will define below), then the optimal measure will be very close to a map, and in fact will be represented by a unique defined function a.e. which is differentiable a.e..\n",
        "\n",
        "And this is where properties of the cost function $c$, especially properties about the derivatives and hessian of $c$ plays a large role in the uniqueness and regularity of optimal transport measures. \n",
        "\n",
        "But there's more. Because Kantorovich has rephrased Monge as a linear optimization program, but which now has a dual maximization program. And this is where the understanding of Fenchel-Legendre transforms and duals is very important, and really a very important (but accessible) technical aspect to OT. \n",
        "\n",
        "Remark. For the students, I would recommend putting in your time with the Legendre-Fenchel transform of proper lower semicontinuous convex functions on $R^n$. \n",
        "\n",
        "[First five or ten minutes understandeable to everyone]\n",
        "\n",
        "The general setup of OT is this: \n",
        "We have a source space $X$ with source measure $\\sigma$, say, $\\sigma = f(x) dx$ on the real line. \n",
        "We have target space $Y$ with target measure $\\tau$, say, $\\tau = g(y) dy$ on the real line $Y={\\bf{R}}^1$. [Insert image of $f(x) dx$ and $g(y) dy$ graphs on slide]. \n",
        "Now consider the set of couplings $\\pi$ (or correlations between the source and target. This is a measure $\\pi$ on the product $X \\times Y$ which satisfies conditions on the marginals, namely $pr_Y \\#(\\pi) = \\tau$ and $pr_X \\#(\\pi) = \\sigma$. \n",
        "\n",
        "(Aside:) A briefer way to phrase the transport problem, as studied by Monge (reference?) and Ampere (reference?), is to ask for measurable maps $F: X \\to Y$ which satisfy $F\\#(\\sigma)=\\tau$ and which minimize a cost functional [insert integral]. \n",
        "\n",
        "If $\\sigma$, $\\tau$ are discrete measures, then the set of all semicouplings has form doubly-stochastic $dim(X) \\times dim(Y)$ matrices $\\pi = \\{ a_{ij} \\}$, and the sum of all rows and columns are prescribed and equal to the respective densities $f(x)$ and $g(y)$. The set of all semicouplings is a weak-$\\ast$ compact and convex subset of the space of all Borel-Radon measures on the product $X \\times Y$. \n",
        "\n",
        "The above is Kantorovich's linearization of the Monge problem, where we don't seek maps (yet!) but begin with measures which have fixed marginals.\n",
        "\n",
        "Remark 1. There always exists joint distributions / correlations / couplings between $\\sigma$ and $\\tau$ if [hypotheses]. Proof: we have the maximally correlated distribution, namely the \"tensor product\" of the measures $\\sigma \\otimes \\tau$. A normalization constant is here required ... . And indeed there exists couplings only if $\\int_X \\sigma \\geq \\int_Y \\tau$. \n",
        "\n",
        "With Kantorovich we begin studying a weak-$\\ast$ closed subset of the set of couplings, and here some basic functional analysis enters. This guarantees the existence of minimizers relative to weak-$\\ast$ continuous functionals. \n",
        "\n",
        "Remark 2. The Monge problem is very difficult because it's hard to parameterize the space of maps which pushforward $\\sigma$ onto $\\tau$. \n",
        "\n",
        "The main result at the beginning of OT is Brenier-McCann-[] theorem on the existence and a.e. uniqueness of optimal transport maps. [Insert technical statement].\n",
        "\n",
        "Linear problem: $f \\cdot 1 = \\sigma$ and ${}^t 1 \\cdot f =\\tau$. So the correlation matrix $f$ has a right and a left condition. [Check].\n",
        "\n",
        "So far we have not really introduced the dual program, which really is more explicit in a way, and where all the details are hidden. This is $$\\min_\\pi \\int_{X\\times Y} c(x,y) d\\pi(x,y) = \\max_{-\\phi(x)+\\psi(y) \\leq c(x,y)} -\\int_X \\phi(x) d\\sigma(x)+ \\int_Y \\psi(y) d\\tau(y).$$\n",
        "\n",
        "The maximum can be replaced with $c$-concave potentials $\\phi=\\psi^c(x)$ where $\\psi^{cc} = \\psi$. So we have $$\\min_\\pi C(\\pi) = \\max_{\\psi~\\text{~c-concave}} J(\\psi) = \\max (-\\int_X \\psi^c d\\sigma + \\int_Y \\psi d\\tau).$$ And this equality between the max and the min, i.e. there is no duality gap is extremely important for applications. \n",
        "\n",
        "Key fact: the $c$-optimal transport is supported on the graph of the $c$-subdifferential of the $c$-concave potential $\\psi$ maximizing the dual potential.\n",
        "\n",
        "[Insert definition of subdifferential : it's the case of equality!]\n",
        "\n",
        "Example: the case of $L^1$ transport. Personally, I use OT for topology, and the nonstrict convexity of the $L^1$ euclidean norm means there is not a continuous displacement interpolation between the source and target measures. The transport is effectively a teleportation. The mass disappears at the source and reappears at the target, i.e. there is no _local_ conservation of mass (although there is of course a global conservation of mass). \n",
        "\n",
        "However the $L^1$ transport problem has the form $\\phi^{cc}=\\phi$ when $c=d^1$ and $\\phi$ is 1-Lipschitz. This is how we get the WGAN formulation, where we might say $W_1GAN$ formulation:\n",
        "\n",
        "$$\\min \\pi \\int d^1(x,y) d\\pi(x,y) = \\sup_{\\phi~\\text{~1-Lipschitz}} -\\int_X \\phi(x) d\\sigma(x) +\\int_Y \\phi(y) d\\tau(y).$$\n"
      ],
      "metadata": {
        "id": "Cu8UeXro2c8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hide\n",
        "\n",
        "# Sample Code from PythonOT. "
      ],
      "metadata": {
        "id": "oCv6J7ADFG5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hide\n",
        "\n",
        "# Author: Remi Flamary, Nicolas Courty, Aurelie Boisbunon\n",
        "#\n",
        "# License: MIT License\n",
        "# sphinx_gallery_thumbnail_number = 1\n",
        "\n",
        "!pip install pot"
      ],
      "metadata": {
        "id": "VAURLHqx_AFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hide\n",
        "\n",
        "import numpy as np  # always need it\n",
        "import pylab as pl  # do the plots\n",
        "import ot  # ot\n",
        "import time\n",
        "\n",
        "\n",
        "help(ot.dist)\n",
        "\n",
        "# dist returns distance metric over a collection of samples relative to different costs. \n",
        "# also imports more distances from a certain scipy package. I find the spherical costs interesting, \n",
        "# far field reflector cost, quadratic cost. ... But all these costs are \"attractive\", and they are kind of interchangeable."
      ],
      "metadata": {
        "id": "3FbG4NbS_Bfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hide\n",
        "\n",
        "data = np.load('../data/manhattan.npz')\n",
        "\n",
        "bakery_pos = data['bakery_pos']\n",
        "bakery_prod = data['bakery_prod']\n",
        "cafe_pos = data['cafe_pos']\n",
        "cafe_prod = data['cafe_prod']\n",
        "Imap = data['Imap']\n",
        "\n",
        "print('Bakery production: {}'.format(bakery_prod))\n",
        "print('Cafe sale: {}'.format(cafe_prod))\n",
        "print('Total croissants : {}'.format(cafe_prod.sum()))"
      ],
      "metadata": {
        "id": "OIhUuIIjgNnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hide\n",
        "\n",
        "X1 = np.asarray([ [1, 0, 0], [0, 1, 1] ])\n",
        "X2 = np.asarray([[0, 0, 1], [0,0,0], [0,0,0], [1,1,1]])\n",
        "\n",
        "ot.dist(X1, X2)"
      ],
      "metadata": {
        "id": "JfiDRIJ5_sII"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}