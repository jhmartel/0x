{
  
    
        "post0": {
            "title": "GR, OT, Costs, Part 2.",
            "content": ". Costs and Optimal Transport (OT) . What is OT about? Everybody knows its about costs, and specifically trying to minimize the expected cost of a coupling or semicoupling or correlation between a source $(X, sigma)$ and a target $(Y, tau)$. But what is the cost $c(x,y)$ of transporting a unit mass from $x$ to a unit mass at $y$? Here we assume that the measures $ sigma, tau$ represent matter which needs be conserved. So if a unit mass at $x$ is transported to a unit mass at $y$, then the intermediate masses, say $ mu_s$ for some parameter $s$, needs to have total mass $ int mu_s$ equal to $1$ for all parameters. . A priori, it is difficult to construct costs $c$ between spaces $X, Y$ which occupy different spaces, having no spatial relationship between points $(x,y)$, and having no measure of either near or far, or hot and cold. In case $X,Y$ occupy different universes, then they might be said to be infinitely far apart and the only canonical cost appears to be a constant zero (or constant infinity) cost. Therefore insofar as optimal transport is studying geometric transport, it is necessary that the source and target spaces $X,Y$ have some spatial relations between the various elements. As trivial as this sounds, it is very difficult and important problem to construct interesting geometric costs. . In practice the author finds best results are obtained when the target $Y$ is given as a subset of the source $Y hookrightarrow X$. Interesting topological applications arise when $Y= partial X$ is a type of rational bordification of $X$, e.g. $Y= partial X[t]$ where $X[t] subset X$ is a $ Gamma$-rational excision like Borel-Serre bordifications of locally symmetric spaces. See our thesis for such examples. . The author is also not convinced one can invent en abstracto interesting geometric costs. . So rather we turn to physical models for inspiration. In our view, cost always represents a cost of energy in Joules, and not necessarily of dollars, or kilometers. . So a cost $c(x,y)$ measures an interaction between a unit mass at $x$ and a unit mass at $y$. . In our minds, this tells us that costs $c(x,y)$ represent interaction energies. . In our thesis [Ibid] we compared the properties of attractive costs, e.g. the quadratic geodesic cost $c(x,y)=d(x,y)^2/2$ when $Y subset X$, with the class of so-called repulsive costs. These costs were interesting because the geometry of the singularities of $c$-optimal transports had very different structures. . We were motivated by electrodynamics. Heuristically, the attractive costs represents interaction energies between oppositely charged positive source and and negatively charged target configurations. The repulsive cost represents interaction energies between, say, positive source and positive target configurations. We recall that opposite charges attract and like charges repel, hence the terminology. This final idiom that like charges repel has a very interesting modification when interaction energy is measured via Weber&#39;s potential, but we leave this for future topic. This is briefly discussed here. . GR and OT . We would like to continue to develop our ideas on GR and OT. This seems popular subject, and I know we have an interesting viewpoint on the whole situation. Where are we? In previous section we were discussing cost as energy. This implies that the expected cost, or integral $ int c(x,y) d pi(x,y)$ also has well-defined units of energy. Bearing this in mind, let us now continue our discussion of GR and OT. . As we discussed here what Robert calls the Lorentz distance $ ell( sigma, tau)$ between measures $ sigma, tau$ on $ mathbf{R}^{3,1}$ and which he interprets as the &quot;expected maximal proper time between the events $ mu, nu$&quot; is not readily interpreted as an energy, and so we find it difficult to accept $ ell$ as a suitable cost in the classical sense. . And so we return to the question &quot;what does $ ell(x,y)$ represent given events $x,y$? &quot; Given the above discussion, let us then also ask: &quot;what does the additive expected value represent $ int ell (x,y) d pi(x,y)$ when $ pi$ is a coupling measure between events $ sigma, tau$? Our point here is that the cost has definite energy units in the classical setting, and these energy units are additive, and therefore the integral representing the expected value again has well-defined energy units. However with the Lorentzian distance $ ell$, there are no units to justify or confirm that the additive average is well-defined. Of course, the numerical integral value is well-defined, but there are many other possible modifications. Robert&#39;s paper has anticipated this objection somewhat in his general treatment of $q ell(x,y)^q$ for $0 &lt; q leq 1 $. . Is the above question irrelevant? Some might rationalize it away, and dismiss the objection. They might ask &quot;why should $ ell$ need an interpretation?&quot; or &quot;why should $ ell$ require units?&quot;. . Our response would be, &quot;well, are we looking for something to compute, or are we looking for something to experimentally verify?&quot; If we are just computing values, and if that is considered physics, then okay, we don&#39;t need units. But if physics is to relate to observation, then we necessarily need units. Why? Because units are used to quantify uncertainty. Again, this is the classical viewpoint. . Remark. If the Lorentz-Minkowski metric $ds^2$ was positive definite, then we could happily represent $ ell$ as a sum of positive squares, in which case we have a formula in the units of energy, i.e. kinetic energy assuming that one can define the inertial mass. But in the SR spacetime formulation, there seems no opportunity to introduce inertial mass, and the sum of signed squares has no Riemannian metric meaning. . Problem: Construct Interesting Energetic Costs . So before we digress into a question about GR and OT, let&#39;s pose some problems. Basically the usual quadratic cost $c(x,y)=d(x,y)^2/2$ is taken as the canonical cost on a Riemannian manifold. Thus we witness the same thing with proposals for applying OT to SR and GR, and this is indeed natural. . Our question here is where to find more examples of costs. For as we developed in our thesis, for one example, different costs can generate singularities of very different homotopy type. From our point of view, this depends on whether costs are attractive or repulsive. . For example with an attractive cost, one is typically looking at ground states which collect near the target. However for repulsive costs, the ground states are typically deeply nested in the source domain, i.e. states are being repelled from the target, and look to escape as far away as possible. . We continue to use electrodynamic energies as the basic supply of interesting costs. The author would be open to hearing other recommendations for interesting costs. . m, matter, mass, Mach. . I can&#39;t help myself from making another comment on the challenge of applying OT to GR. In OT one often speaks about mass transport, where it&#39;s always assumed that a continuity equation holds. Thus when the measures are transported there is conservation and nothing lost or gained along the way. . So if OT is to study &quot;mass transport&quot; in the setting of GR, are we to assume that mass also will satisfy local conservation ? In otherwords, what are the measures $ sigma, tau$ actually representing on the spacetime ? . Wal Thornhill has made this point himself, that among the greatest hazards and sources of confusion in physics is the unfortunate coincidence that both mass and matter begin with the same letter &quot;m&quot;. . Really no joke. That&#39;s the cause of all the trouble. What happens is mathematicians and physicists both get lazy and begin to interpret &quot;m&quot; for matter and mass as if they are equivalent or interchangeable. This possibly originates in Newton&#39;s own non-definition of mass as simply the presence of immediate ponderable matter, and Newton assumed that there was some unspecified constant of proportionality between mass and matter and so &quot;up to a constant which we can set to $1$&quot; both &quot;m[atter]&quot; and &quot;m[ass]&quot; became confused with the letter $m$. . Einstein&#39;s Equivalence Principle is another source of confusing the gravitational mass $m_g$ of an object (which following Newton is something vaguely defined like the quantity of gravitational charge, or in otherwords quantity of matter) with the inertial mass $m_i$. Thus Einstein&#39;s argument that $m_g=m_i$ is another source of confusion. The argument against Einstein&#39;s equivalence principle is elementary, and recognized by Einstein himself that rotating bodies do not admit global inertial frames! Therefore the inertial frames used to convert the gravitational potential into an inertial reference frame is only defined locally on the tangent space. It is very limited first-order observation. . Amazing there is another &quot;m&quot; that enters the problem of &quot;matter&quot; and &quot;mass&quot;, namely Mach! Because Mach proposed that the inertial mass $m_i$ must be defined as the potential energy of the body relative to the fixed stars at infinity. What are the implications? Namely that . matter can neither be created nore destroyed . while inertial mass is variable depending on the interaction of the matter with the matter of the fixed stars at infinity. . This is essentially my understanding of AKT Assis&#39; development of Relational Mechanics. This is also Halton Arp&#39;s interpretation of the observed intrinsic red shifts of quasars which are visibly interacting with nearby systems. Arp&#39;s idea was that, quasars are creation hotspots in the universe, where newly created atoms have less mass because they have been interacting with only a limited part of the universe for a short period of time. Therefore their inertial mass is much smaller, and therefore the wave lengths emitted by the atoms is increased. This increased wave length is caused not by usual red shift velocity mechanism, but by the Machian dependance of inertial mass with the other matter in the universe, and these matter-to-matter signals take time. This is the meaning of the intrinsic red shift, as opposed to the Hubble-Einstein velocity red shift. Further details can be found in Arp&#39;s book &quot;Seeing Red&quot;. .",
            "url": "https://jhmartel.github.io/fp/einstein/sr/ot/lorentz/2022/04/27/GR_OT_Part2_Costs.html",
            "relUrl": "/einstein/sr/ot/lorentz/2022/04/27/GR_OT_Part2_Costs.html",
            "date": " • Apr 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Einstein and Maxwell",
            "content": ". We&#39;ve been working on an essay on the foundations of special relativity (SR). Why do we invest so much time and effort into SR foundations ? Well honestly because i think the foundations are never taught, so there&#39;s alot to say. Moreover the SR converts tend to ignore foundations, evading them and jumping ahead to their conclusions. So the task of foundations is typically neglected by adherents, and it&#39;s left to the skeptics to develop the foundational issues. And the student of the history of SR will know that there has always been a strong skeptic school in SR (and GR) and this school frequently included Einstein himself at various times in his life, and for good reason. There is much to critically examine in the SR theory, and this the purpose of our essay. . Einstein SR and Maxwell . Einstein&#39;s theory of special relativity (SR) arose from Einstein&#39;s study of Maxwell&#39;s equations (ME) circa 1870 AD. But what is the logical and mathematical relation between SR and Maxwell? This is interesting question because they are essentially antagonistic. Although Einstein was much influenced by the Maxwellian field theory viewpoint, his own early work (1905) was based on the antithetical photon model of light. . Briefly, by Maxwell equations we understand that in a given reference frame $K$ we have the existence of electric and magnetic fields $E,B$ satisfying the four equations on $div(E), div(B)$ and $curl(E)$ and $curl(B)$ relative to a charge volume density $ rho$ and electric current density $J$. In vacuum where $ rho=0$ and $J=0$, composing the first-order Maxwell equations together yields the second-order fact that the coordinate components of $E,B$ satisfy wave equations with speed of propagation $c= sqrt{ epsilon_0 mu_0}$. This usually leads to the idea that electromagnetic field disturbances travel at the speed of $c$ in aether. And indeed Maxwell&#39;s equations expressly assume an aether as the medium by the which the electromagnetic radiation travels. . Now this author does not really accept Maxwell&#39;s field equations as being satisfactory. For example, the magnetic field $B$ is not a rectifiable or reifiable field, meaning it has only potential and not any material substance. The same could be said for Maxwell&#39;s electric field, which again is a potential field describing the force experienced by a charged test particle. This is the so-called continental field-theoretic viewpoint after Maxwell, etc. . However Maxwell&#39;s equations were not satisfactory in their predictions on the photoelectric effect. For example, is light a disturbance in the electric or the magnetic field? If light is such a disturbance, then Maxwell equations predict the interaction of the $E$-wave (or is it $B$-wave) with charged test particles. . Here it&#39;s interesting to compare Einstein&#39;s 1905 explanation of the photoelectric effect using the photon particle theory of light. Thus we tend to interpret Einstein&#39;s developments of SR from a photon or corpuscular point of view. . Problem: The classical homogeneous wave equation has the property of the velocity being dependant on the receiver velocity relative to the medium. But SR argues that the assumption on the &quot;rectilinear uniform propagation of light&quot; somehow yields a wave equation where velocity is receiver independant. But how? [We do not address this important issue here]. . SR and Lorentz Groups . The null result of the Michelson-Morley experiments led to Einstein&#39;s postulating the Lorentz transformations relating space and time variables $x,t$. Undoubtedly the theory of SR is summarized in the representations of the Lorentz group of linear transformations, namely the isometry group designated $O(ds^2)=O(3,1)$ and its standard linear action on ${ bf{R}}^{3,1}$. . For the mathematician, once a single linear representation is given, there are many algebraic constructions possible to obtain further representations, for example the symmetric and alternating representations. We develop this idea further to try and bridge the assumptions of SR to Maxwell&#39;s equations, and especially the wave equation. . Now we discuss several group representations (i.e. linear group actions). . First we begin with the standard linear representation $$ rho_0:{ bf{R}}^{1,3} times L to { bf{R}}^{1,3}$$ which is the linear representation $ rho_0$ represented by left matrix multiplication $(v, lambda) mapsto lambda.v$. . Next we dualize. . Let $C({ bf{R}}^{3,1})$ be the space of polynomial functions on the space. Abbreviate $C:=C({ bf{R}}^{3,1})$. Naturally we assemble $C$ from the dual functionals $ lambda in {({ bf{R}}^{3,1})}^*$. Taking products and polynomials in the dual functions $ lambda$ we obtain the contragradient represention $$ rho_0^*:C( { bf{R}}^{3,1}) times L to C({ bf{R}}^{3,1}). $$ . The idea is that the vector spaces $V$ and $V^*$ are isomorphic (non canonically) in finite dimensions. Moreover the algebra generated by $V^*$ yields an (infinite-dimensional) space of polynomial functions on $V$. . Now what are vector fields? . In differential topology, the vector fields $ frac{ partial }{ partial x}$ act on functions as a derivation, i.e. as linear maps $$ frac{ partial }{ partial x}: C to C $$ satisfying Liebniz product formula. Iterating the derivations $ frac{ partial }{ partial x} circ frac{ partial }{ partial y}= frac{ partial^2 }{ partial x partial y}$ leads to the usual differential operators, etc.. . Consider the d&#39;Alembert operator $$ square:= frac{-1}{c^2} frac{ partial^2}{ partial t^2} + frac{ partial^2}{ partial x^2}+ frac{ partial^2}{ partial y^2}+ frac{ partial^2}{ partial z^2} .$$ . Now our main proposal is that the Minkowski squared line element $ds^2$ is dual in a linear algebraic sense to the d&#39;Alembert operator $ square$. . The Lorentz invariance of $ square$ shows the solutions to the homogeneous wave equation (HWE) are Lorentz covariant and $ square phi =0$ if and only if $ square lambda cdot phi =0$ for every Lorentz transformation $ lambda in L$. The corresponding fact for $ds^2$ is that the null cone $ds^2=0$ is Lorentz covariant. . For example, the quadratic form representing $ds^2$ satisfies $ square h=0$ where $h=-c^2t^2+ frac{1}{3}(x^2+y^2+z^2)$. . Now Einstein&#39;s (A12) postulates the uniform rectilinear propagation of light in vacuum. This would suggest a corpuscular model of light, being represented as affine parameterized lines $$s mapsto (s, x(s), y(s), z(s))=(s, gamma(s)) $$ in ${ bf{R}}^{3,1}$ satisfying $D^2_{ss} gamma =0$. . Is the equation $D^2_{ss} gamma=0$ Lorentz covariant? (Yes?) . But what are the corresponding &quot;uniform rectilinear&quot; solutions $ phi$ for the dual HWE: $~~ square phi=0$ ? Compare this. . An idea: there has always been correspondance between lines in $V$ (one-dimensional linear subspaces) and quadratic functionals via the Segre embedding, or $ lambda mapsto lambda^2$ where $ lambda in V^*$ is a linear functional. . The following questions will be answered below: . Are the quadratic functions $q(x)=h(v,x)^2/2$ solutions to $ square =0$ for null vector $v in N$? . | Can we find quadratic functions $q$ whose level sets are everywhere orthogonal to the null cone $N$ ? . | . The idea would be to derive some canonical solutions $ square q=0$ from quadratics arising from vectors on the null cone. . If $v$ belongs to null cone, then $q(x):=h(v,x)^2/2$ for $x in V$ defines a quadratic function on $V$ with $q(v)=h(v,v)^2=0$. . It&#39;s clear that $q$ is minimized along $v^ perp$, and that $v in v^ perp$. Moreover the differential of $q(x)=q(t,x)$ satisfies $dq|_x=h(v,x)v$. . Lemma. For every vector $v in { bf{R}}^{3,1}$, let $q(x):=h(v,x)^2/2$ be the quadratic form defined by $v$. Then $ square q=0$ if and only if $v in N$ and $h(v,v)=0$. . Proof. We claim that $ square q=h(v,v)$ when $q(u)=h(v,u)^2/2$. . If the vector $v$ has coordinates $v= langle v_t, v_x, v_y, v_z rangle$, then $h(v,x)^2$ is equal to $$(-v_t t + v_xx+ v_yy+ v_zz)^2,$$ which is equal to $$v_t^2 t^2 +v_x^2 x^2 + v_y^2 y^2 + v_z^2 z^2 + (mixed~ terms).$$ Therefore applying d&#39;Alembert&#39;s operator we find $$ square q =2( -v_t^2+v_x^2 + v_y^2 + v_z^2), $$ since $ square(mixed~~terms)=0$ and the claim follows. . Therefore we obtain a simple class of homogeneous quadratic functions in $(x,t)$ which satisfy HWE. . Levi-Civita and Einstein&#39;s Geometric Optics . In Levi-Civita&#39;s &quot;Absolute Differential Calculus&quot;, Einstein&#39;s applications of SR to geometric optics (theory of light propagation) is summarized in two equations. . First we have $$ds^2=0$$ and $$ delta int ds=0.$$ . Here $$ds^2=-c^2 dt^2 + dx^2+dy^2+dz^2$$ is the Lorentzian quadratic form. The Lorentz invariance of $ds^2$ implies the null cone $ds=0$ is Lorentz invariant. . In the second equation $ delta$ is the variational derivative of the functional $ gamma mapsto int_ gamma ds$, and the equation is an expression in the calculus of variations similar to Hamilton&#39;s principle and Fermat&#39;s least time principle. There is a difficulty in reconciling the above equations because the line element $ds$ vanishes identically on the null cone, and therefore the functional $ gamma mapsto int_ gamma ds$ is identically zero on curves $ gamma$ which are everywhere tangent to the null cone. This difficulty is admitted in Levi-Civita&#39;s textbook. .",
            "url": "https://jhmartel.github.io/fp/einstein/maxwell/wave%20equation/lorentz/sr/2022/04/26/Einstein_Maxwell.html",
            "relUrl": "/einstein/maxwell/wave%20equation/lorentz/sr/2022/04/26/Einstein_Maxwell.html",
            "date": " • Apr 26, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "GR + OT. Part 1.",
            "content": ". I recently watched Yann Brenier&#39;s YT lecture on Optimal Transport (OT) and General Relativity (GR). He mentioned Professor McCann&#39;s GRO paper. The question ``How to apply OT to GR ?&quot; seems to be gaining attention. But as Brenier suggested, there possibly appears some arrogance in the OT theorists who believe that OT is readymade to make a breakthrough in the GR field. . I have my own thoughts on the problem.T he trouble is that GR is a very radical paradigm for thinking about physics, especially about energy which is notoriously undefined (and undefinable!) in GR. Likewise work is undefined in GR. Thus it&#39;s basically impossible to properly relate thermodynamics to GR. See mathoverflow, physics.stackexchange for numerous questions about the impossibility of really defining energy tensors which satisfy a conservation law, e.g. 1, 2. These difficulties gave Einstein alot of grief throughout his life. . In OT, everything is generally controlled by the geometry of the cost $c: X times Y to mathbf{R} cup {+ infty }$, where $(X, sigma)$ and $(Y, tau)$ are the source and target measure spaces, respectively. But cost is really more properly understood as energy. . What is the cost of transporting/correlating a unit source mass $dx$ to a unit target mass $dy$ ? Well... isn&#39;t it really the energy required to transport/correlate? . Thus when OT studies couplings and semicoupling measures $ pi$ between the source measure $ sigma$ and target $ tau$, the optimization problem is really about the min energy states, i.e. ground states. So OT is already positioned to contribute to GR, as soon as GR can define energy! . For example, if we consider Professor McCann&#39;s paper, we see that path integrals of $ds&#39;:= sqrt{-ds^2}$ along so-called timelike curves lead to his definition of $ ell(x,y;q)$ for a parameter $0 &lt; q leq 1$. At $q=1$ the function $ ell(x,y)$ is like the Lorentz &quot;distance&quot; (caution this is misnomer, since $ ell$ satisfies a reverse triangle inequality!). The function is frequently related to the so-called proper time function $d tau$ defined by $ds&#39;=cd tau$. Since we do not readily admit that $ds&#39;$ has units of $[length]$, we likewise believe it&#39;s an error to generally refer to $d tau$ as having units of $[time]$. While $ds&#39;$ and $ ell$ do represent covariant scalars, we consider it antithetical to the premise of GR to consider these absolute scalars as having any physical units. . So Prof. McCann&#39;s interpretation of the &quot;Lorentz cost&quot; $$ ell( mu, nu)= sup_{ pi} [ int ell(x,y)^{1/q}~ d pi(x,y)~]^q, ~~0 &lt; q leq 1$$ as representing the quote &quot;maximum expected proper-time which can elapse between the distribution of events $ mu, nu$ &quot; is an interesting heuristic, but perhaps not a strictly proper GR interpretation. . But another trouble with the differential geometry of GR is that the Minkowski-Lorentz quadratic forms $g=ds^2=-c^2dt^2 + dx^2+dy^2+dz^2$ is a unit-less number. This is where the absolute part of the absolute differential calculus makes itself known: whatever real number is being represented by $ sqrt{-ds^2}$, it has no ``physical meaning&quot;. . Where does the proper time interpretation come from? The interpretation comes from the use of a so-called &quot;instantaneous rest frame&quot;. But how much information can a particular choice of coordinate system provide? This requires the observer to find coordinates $( tau, xi, eta, zeta)$ where $ tau$ represents ``time &quot; and all the partial derivatives vanish $$ frac{ partial xi}{ partial tau}= frac{ partial eta}{ partial tau}= frac{ partial zeta}{ partial tau}=0.$$ In this particular coordinate system one finds $ds^2=-c^2d tau^2$ and $ds&#39;=c ~ d tau$. But what does this computation really show? We consider it less persuasive than it might appear : can we really conclude that $ds&#39;$ has units of $[length]$ or that $ds&#39;/c$ has units of $[time]$, based on the form of the equation in one coordinate system ? . Conclusion. . Our point is that the tensor calculus approach to GR requires users to basically &quot;surrender their units, rigid rods and rulers at the door&quot;. Once inside the covariant category, the rods no more represent objective lengths. Irrespective of their material composition, the Lorentz transformation formulas take over and contract what was otherwise incontractible. The users themselves will see no contraction because also their corresponding &quot;proper times&quot; will be contracted. So when the Lorentzian scalar $ds&#39;$ is used by the Riemannian geometer, a careful mind needs to not readily confuse the units of $ds&#39;$ as representing $[length]$ in the timelike future directions. . These opinions originate from around year 2013--2018, when I really spent alot of time in symplectic geometry, almost-complex structures, pseudo-Riemannian and Lorentzian geometry, and took long road to realize that importing Riemannian definitions into pseudo-Riemannian structures does not yield metric Riemannian results. For example, a function $ ell(x,y)$ which satisfies a reverse triangle inequality $$ ell(x,y) geq ell(x,z)+ ell(z,y)$$ can not really correspond to a units of $[length]$. Nonetheless it&#39;s common to see triangles with relabelled edges and where the lengths in no way correspond to the length in the image. . Here looks to be very thorough introduction to the current differential geometric approach to energy in GR. I&#39;m vaguely aware of the ADM definition, originating with Weyl I believe, and which converts the covariant divergence free $ nabla_i T^{ij}=0$ into a local integral conservation equation. .",
            "url": "https://jhmartel.github.io/fp/einstein/gr/ot/units/tensors/2022/04/24/GR_1.html",
            "relUrl": "/einstein/gr/ot/units/tensors/2022/04/24/GR_1.html",
            "date": " • Apr 24, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Alexandrov and Souls. Part 1.",
            "content": ". Here is available a very rough work-in-progress. I&#39;ve let the idea rest for seventeen months. It&#39;s difficult to illustrate the idea in python, and there appears no application of python to Alexandrov geometry yet. . What is Alexandrov geometry? . Introductions and references are available from Alexander, Kapovitch, Petrunin. The subject is notoriously difficult. The original paper of Burago, Gromov, Perelman is still useful. . An Alexandrov space $(X,d)$ is a fat and round metric space, like a sphere or cube but possibly with corners and sharp angles, and where triangles are fat. Examples include: convex sets $C$, the boundaries of convex sets $ partial C$, affine space $ mathbf{R}^d$. There are several important metric constructions by which spaces with curvature bounded below ($CBB[ kappa]$ in the notation of AKP). . We are interested in the singular mm-spaces, so we use the synthetic definition of sectional curvature and not necessarily the Gaussian definition of differential Riemannian geometry. Alexandrov spaces have sectional curvature $ kappa geq 0$, which implies that every geodesic triangle $ Delta(a,b,c)$ in $X$ is fatter than the comparison triangle $ tilde{ Delta}$ in $ mathbf{R}^2$. . In Alexandrov geometry, geodesics frequently focus and collide. Initially geodesic rays might appear to be orthogonal, but at a not-too-faraway time, the rays will focus and converge back to a point. After this refocussing the geodesics might or might not diverge again to infinity. Positive sectional curvature tends to manifest in general relativity spacetimes, where the presence of mass (attractive matter) tends to cause light rays to focus and converge. . Our goal is a general method for constructing the souls of singular finite-dimensional Alexandrov spaces. . The original result on souls was achieved by G. Perelman (1994), building on the work of Gromoll, Meyer, Cheeger. Perelman&#39;s result in the Riemannian setting was that the souls $S$ of Riemannian Alexandrov spaces $(X,g)$ had the property that: $X$ was diffeomorphic to the normal bundle of $S$. . So what remains to be proved in the singular setting? . On a singular Alexandrov space, the space of directions at every point is isometric to an Alexandrov space of curvature $ kappa geq 1$. The metric distance on the space of directions $ Sigma_p X$ at a point $x$ is defined by the angle between the directions. Alexandrov spaces (curvature bounded below by zero) have well-defined angles and directions. For almost all points, this space of directions is isometric to a $d-1$ dimensional sphere $ mathbf{S}^{d-1}$. This is well-known regularity property of Alexandrov spaces, namely that almost all points are regular. This is analogous to the fact in convex analysis that proper lower semicontinuous convex functions are differentiable almost everywhere. . The real challenge in the singular setting is to define gradient flows which are naturally defined and extend through the singular points. . Python and Alexandrov? . Our approach to mathematics is based on discovery. So instead of trying to prove everything a priori, we prefer to experiment and discover what is true. But how to use python to study Alexandrov spaces? It&#39;s not clear... . There are many analogies between lsc (lower semicontinuous) proper convex functions $f: mathbf{R}^d to mathbf{R} cup {+ infty }$ and Alexandrov spaces. For example, the regularity of Alexandrov spaces follows from the fact that: lsc proper convex functions are differentiable almost-everywhere on their domain. This is because the gradient $D f$ is Lipschitz on its domain, and therefore differentiable almost-everywhere. Therefore $f$ is even twice-differentiable almost everywhere on its domain. . Similarly, if an Alexandrov space contains a doubly-ended geodesic ray, then the Splitting theorem says $X= mathbf{R}^1 times X_0$ where $X_0$ is again Alexandrov. For convex lsc proper functions, the analogous fact is this: if the graph of the derivative $Df$ contains a double ended straight line, then up to a change of variable, $f$ can be factored as $f= ell(x_1) + f_0(x_2, ldots, x_d)$ where $ ell$ is affine and $f_0$ is a convex function which only depends on the remaining variables $x_2, ldots, x_d$. (There may be slight error here, but this is essentially the idea as i learned from Prof. R.J. McCann.) . But the proper lsc convex functions are something like the local theory of Alexandrov spaces. For example, a difficult result in the foundations of Alexandrov geometry is Toponogov&#39;s Globalization theorem, namely: if a space satisfies Toponogov comparison everywhere on small neighborhoods, then the space satisfies Toponogov comparison globally. . Although we should note that the convex analysis analog does not readily lead to a proof of Toponogov&#39;s Globalization theorem, which is very difficult result in foundations of Alexandrov geometry. For functions $f$ on $ mathbf{R}^d$ the question is: if $f$ is locally convex, then prove $f$ is globally convex. .",
            "url": "https://jhmartel.github.io/fp/alexandrov/souls/singular/2022/04/22/Alexandrov.html",
            "relUrl": "/alexandrov/souls/singular/2022/04/22/Alexandrov.html",
            "date": " • Apr 22, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Yao's Millionaire's Problem. Part 1.",
            "content": ". The purpose of this article is to investigate whether there is strategy or skill possible in the following variation of Yao&#39;s &quot;Millionaire Problem&quot;. . Here is the game. We have a huge grid $ mathbf{R}^2$. Now let two players $A,B$ have secret locations $s_A=(x_A, y_A)$ and $s_B=(x_B, y_B)$. These secrets are points in the euclidean plane $ mathbf{R}^2$. . Now the players $A, B$ are going to take turns guessing affine functions (or affine lines in $ mathbf{R}^2$) and the first player to guess an affine function which separates the secrets wins! . The gameplay is something like this: The players $A,B$ take turns. If player $A$ goes first, then player $A$ chooses an affine function $ ell$ on $ mathbf{R}^2$, and asks player $B$ to reply with the sign of $ ell(s_B)$. We require that $B$ replies honestly with $sgn( ell(s_B))$. This is the end of player $A$&#39;s turn. If $ ell$ separates the secrets, then player A wins. Otherwise it&#39;s player B&#39;s turn. Next player $B$ chooses an affine function $ ell&#39;$, and asks player $A$ to reply with the sign of $ ell&#39;(s_A)$. Once player $A$ replies, then this is the end of player $B$&#39;s turn. Again, if $ ell&#39;$ separates the secrets, then player B wins. Otherwise it&#39;s player A&#39;s turn. . The object of the game is to determine an affine function $ ell$ which separates the secrets, i.e. for which $ sgn( ell(s_A)) neq sgn( ell(s_B)).$ The first player to demonstrate an affine function which separates the secrets wins! . Our interest is to find optimal strategies for this game. Firstly, we have to consider whether any strategy is even possible. For example, can player $A$ use the cumulative history of both player $A$ and $B$&#39;s affine guesses to better inform their next guess? For example, if player $A$ guesses an affine function $ ell$ which does not separate, then player $B$ can use the knowledge of their own private secret to determine which halfspace contains $s_A$. And indeed, by the same reasoning player $A$ can use their knowledge of $s_A$ to likewise determine which halfspace contains $s_B$. So obviously the initial distribution $d lambda$ is updated to the restricted distribution $d lambda cdot 1_H$, where $H$ is the halfspace defined by $ ell$ and containing $s_A, s_B$. With successive guesses, the distribution becomes a descending chain of closed convex sets, namely the intersection of successive halfspaces, having the form $$d lambda leadsto d lambda cdot 1_H leadsto d lambda cdot 1_H 1_{H&#39;} leadsto d lambda cdot 1_H 1_{H&#39;} 1_{H&#39;&#39;} leadsto cdots. $$ . The notation is somewhat strange, but simply expresses that we remain uncertain of the specific location of the secrets $s_A, s_B$, except we know the possibly location is becoming more restricted. . In the millionaire game, the players $A,B$ have an interest in privacy. Their secrets $s_A, s_B$ are intended to be secret. This means the players $A,B$ might not choose affine functions which potentially reveal information about their own secrets. In practice this means players determined to maintain their privacy will always choose affine functions which do not bound compact convex sets. Similarly, an opponent will not readily choose affine functions which separates the domain into a bounded component, since the probability that the opponent&#39;s secret lies in the bounded component is relatively small, while the probability of its lying in the unbounded component is much greater. . The subject of so-called zero knowledge proofs in cryptography is related to the millionaires problem. Here we try to find a balance where the players can choose to reveal as much as they wish of their own balances, while their own guesses are signals/indications in-themselves of the secret balance. . Our question is whether there is any strategy or skill in this game. What is the optimal strategy? Can the player use the knowledge of the opponent&#39;s affine functions to improve their own selection of affine function?? . import numpy as np import matplotlib.pyplot as plt # Now we simulate the millionaire problem on the euclidean two-dimensional plane. # For convenience we rename the players $A,B$ as players $+1, -1$, respectively. # for testing purposes we suppose the players A,B have secrets below: #s_A=input(&quot;What is player A&#39;s secret position?&quot;) s_A=[16,0] s_A=np.array(s_A) #s_B=input(&quot;What is player B&#39;s secret position?&quot;) s_B=[0, 0.2] s_B=np.array(s_B) # now we define some basic functions, i.e. to compute affine functions based on # their normal n and height b. def affine(n,x,b): n=np.array(n) x=np.array(x) # return n.dot(x)+b return n[0]*x[0]+n[1]*x[1] + b # to protect the secret we really only need the sign of the affine function. def sign(x_Real): if x_Real&lt;0: return -1 else: return +1 # here t defines the test function, which returns True iff the affine function # separates the secrets. True is returned if the signs of the affine function # evaluated on the secrets are not equal. def t(n,b): n=np.array(n) if sign(affine(n,s_A,b)) != sign(affine(n,s_B, b)): return True else: return False . #initial conditions. outcome=False history=[] vector_history=[] player=+1 i=0 color=[] while outcome == False: print(&quot; n Player &quot; + str(player) + &quot;&#39;s turn to play:&quot; ) print(&quot;Given the history &quot; + str(history) + &quot; choose your affine function:&quot;) n0 = float(input()) n1 = float(input()) b = float(input()) history = history + [[n0, n1, b]] vector_history=vector_history + [[n0, n1]] i=i+1 if t([n0, n1], b) == True: outcome = True print(&quot;Winner! Player &quot; + str(player)+ &quot; has separated the secrets with &quot; + str([n0, n1, b]) + &quot;. End of Game!&quot;) else: print(&quot;Fail! Player &quot; + str(player) + &quot; has failed to separate the secrets... End of turn.&quot;) player=player*(-1) # the following plots the various normals chosen by the players, but we would # prefer to have the half spaces. V=np.array(vector_history) origin=np.array([[0]*i, [0]*i]) plt.quiver(*origin, V[:,0], V[:,1], scale=21) plt.show() . Player 1&#39;s turn to play: Given the history [] choose your affine function: 1 1 0 Fail! Player 1 has failed to separate the secrets... End of turn. . Player -1&#39;s turn to play: Given the history [[1.0, 1.0, 0.0]] choose your affine function: 3 1 0 Fail! Player -1 has failed to separate the secrets... End of turn. . Player 1&#39;s turn to play: Given the history [[1.0, 1.0, 0.0], [3.0, 1.0, 0.0]] choose your affine function: 1 4 0 Fail! Player 1 has failed to separate the secrets... End of turn. . Player -1&#39;s turn to play: Given the history [[1.0, 1.0, 0.0], [3.0, 1.0, 0.0], [1.0, 4.0, 0.0]] choose your affine function: -3 0 -5 Fail! Player -1 has failed to separate the secrets... End of turn. . Player 1&#39;s turn to play: Given the history [[1.0, 1.0, 0.0], [3.0, 1.0, 0.0], [1.0, 4.0, 0.0], [-3.0, 0.0, -5.0]] choose your affine function: -1 -4 2 Winner! Player 1 has separated the secrets with [-1.0, -4.0, 2.0]. End of Game! . The above is a very simple gameplay, where it happens by chance that the two points can be separated by a flat strip, namely the space between two parallel halfspaces. We included the above simply as an example. . [To Do:] . Use matplotlib to plot the halfspaces, and not simply the normal vector, which is what we have above. . | Determine some automatic routine to compete with a human opponent. . | The millionaire&#39;s problem implicitly assumes the players $A,B$ have large funds, i.e. enough to pay for a dinner! Therefore we might need assume our secrets $s_A, s_B$ are sufficiently far from the origin. (?) . | If the domain is essentially infinite, then a certain amount of privacy will always be maintained, because it&#39;s better to bisect the unknown into two halfspaces of equal (possibly infinite) area. If the affine function indeed separates the secrets, then the position of that secret is only known to occupy an infinite area domain, and thus essentially remains private in a restricted sense. Although of course the direction of the secret, and not necessarily its magnitude will be better known to the opponent, i.e. there will be a definite reduction of uncertainty in the direction of the opponents secret, but not necessarily a reduction in uncertainty in its magnitude. . | If an opponent proposes an affine function which separates the domain into a bounded and unbounded component, then that is huge risk for the player, i.e. it&#39;s unlikely that the small bounded domain (chosen at random) will contain the secret as opposed to the infinite domain. At the risk of belabouring the point: a random infinite domain is more likely to contain an unknown secret than a compact domain. We find this an interesting point... . from scipy.spatial import HalfspaceIntersection prehistory = history[:-1] signs=[] sph=[] for x in prehistory: epsilon=sign(affine([x[0], x[1]], s_A, x[2])) signs=signs+[epsilon] sph=sph+[epsilon*np.array(x)] sph=np.array(sph) # for illustration we have the secret s_A as feasible_point. # its interesting question to select a feasible point which # does not reveal too much information about the secrets... # but obviously any point on the convex hull formed by the secrets s_A, s_B # will be a feasible point. But there are many more choices, so which choice reveals # the least information about the secrets s_A, s_B ? I.e. which feasible point can be chosen # which reveals the least information about s_A, s_B? feasible_point = np.array([16.0, 0.0]) halfspaces = sph*(-1) # we need reverse-signs to align with the convention in qhull that # the halfspaces are defined by the inequality Ax+b &lt;= 0. hs = HalfspaceIntersection(halfspaces, feasible_point) import matplotlib.pyplot as plt fig = plt.figure() ax = fig.add_subplot(&#39;111&#39;, aspect=&#39;equal&#39;) xlim, ylim = (-100, 100), (-100, 100) ax.set_xlim(xlim) ax.set_ylim(ylim) x = np.linspace(-100, 100, 1000) symbols = [&#39;-&#39;, &#39;+&#39;, &#39;x&#39;, &#39;*&#39;] signs = [0, 0, -1, -1] fmt = {&quot;color&quot;: None, &quot;edgecolor&quot;: &quot;b&quot;, &quot;alpha&quot;: 0.5} for h, sym, sign in zip(halfspaces, symbols, signs): hlist = h.tolist() fmt[&quot;hatch&quot;] = sym if h[1]== 0: ax.axvline(-h[2]/h[0], label=&#39;{}x+{}y+{}=0&#39;.format(*hlist)) xi = np.linspace(xlim[sign], -h[2]/h[0], 1000) ax.fill_between(xi, ylim[0], ylim[1], **fmt) else: ax.plot(x, (-h[2]-h[0]*x)/h[1], label=&#39;{}x+{}y+{}=0&#39;.format(*hlist)) ax.fill_between(x, (-h[2]-h[0]*x)/h[1], ylim[sign], **fmt) x, y = zip(*hs.intersections) ax.plot(x, y, &#39;o&#39;, markersize=8) . [[ 1. 1. 0.] [ 3. 1. 0.] [ 1. 4. 0.] [ 3. -0. 5.]] &lt;class &#39;numpy.ndarray&#39;&gt; . [&lt;matplotlib.lines.Line2D at 0x7f1a35df01d0&gt;] . The above intersection of halfspaces isn&#39;t what i expected. The complete intersection is the sector in the upper right hand corner. . Now if we are truly taking secret points $s_A, s_B$ at random in $ mathbf{R}^2$, then almost all random choices of affine functions will not separate the secrets. For example, given the homogeneity of $ mathbf{R}^2$, we can consider the secrets $s_A, s_B$ as being extremely close such that they are basically coincident, or at least as seen from a far distance. But then a random choice of affine function is extremely unlikely to contain the two points. Thus it appears that truly random choices of affine functions have essentially zero probability of separating the secrets. . This leads to the next step in our study of the Millionaire Problem, namely where the initial distribution on $ mathbf{R}^2$ is not necessarily uniform. E.g., perhaps we know that the secrets are distributed within a given large radius ball. If we have no other information about the secrets except that it lies somewhere on the large ball $D$, then one probabilistic strategy is to bisect the ball with affine functions, i.e. randomly guess an affine $ ell$ such that $ 1_D 1_{ ell&gt;0}$ and $1_D 1_{ ell &gt; 0}$ have equal area. . But what about privacy? In the previous case where the distribution was uniform on its support on $ mathbf{R}^2$, the privacy of the secrets was maintained so long as the affine functions were unbounded (from above and below). And the opponents would always guess such affine functions because there odds of correctly separating the secrets is significantly increased. But now its possible that the distribution will not be uniform on its support, and therefore the secrets can be learned with a reduction in uncertainty, i.e. perhaps we know that the opponents secret lies in a bounded set, or that 90% percent of the time the opponents secret lies in a given domain. . We remark that there is something like a &quot;maximum likelihood&quot; principle being used here. Now regarding privacy: if the domain $D$ is bounded, then depending on the distribution, the secret might have diminished privacy. This leads to Part 2 of our study, where the secrets are distibuted according to nonuniform distributions $ mu_A$, $ mu_B$ on $ mathbf{R}^2$. . a. What is the optimal strategy for nonuniform initial distributions $ mu_A, mu_B$ ? . b. Can we quantify the &quot;loss&quot; of privacy when the distributions are supported on unbounded domains versus bounded domains? . (To be continued...) .",
            "url": "https://jhmartel.github.io/fp/millionaire/secret/convex%20analysis/2022/04/20/MillionaireGame.html",
            "relUrl": "/millionaire/secret/convex%20analysis/2022/04/20/MillionaireGame.html",
            "date": " • Apr 20, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Note on Economics of Moving and Delivery. Part 1.",
            "content": ". It&#39;s commonly reported that &quot;moving&quot; or &quot;la demenagement&quot; is among the most stressful events for consumers [insert reference]. The essential difficulty is the labour intensity of safely and securely extracting and removing objects from various dwellings. No damage to walls or floors, and all within a controlled fashion. We remind the reader that objects generally have eight vertices, which are all potential hazards to the environment. Americans say moving is more stressful than divorce, having children, survey claims The survey found the average moving cost was over $1,500. . Another difficulty, perhaps unappreciated by the clients, is the challenge of packing the objects into the moving truck. This is a type of entropy problem, since the compressed volume of the moving truck restricts the possible range of motions of the objects. Moving requires alot of work and foresight to efficiently pack all the items securely in a truck. . Another view of the difficulty is this: a house has many rooms, with the objects distributed sparsely throughout the space. However in a moving truck, all the objects need to be compressed into a single room (namely the box of the truck). . Can the clients estimate the volume of all their objects? . Is it possible for them to imagine all the objects to be relocated into a single room?? . There is considerable stress involved in the action of, say, extracting heavy expensive &quot;precious&quot; furniture through various stairwells, corners, basements, etc.. The business of last-minute kijiji moving is even more stressful, for the clients are typically totally unprepared. For example, they might be selling a freezer located in the basement of a townhouse, with a very tight spiral staircase, and the client has arranged for its delivery to another basement appartment. The client might be moving their entire household, or only moving this single item. Or the client has received a new treadmill, and require its transport into the basement. . Building codes and standard construction methods make the extraction and deliveries somewhat easier. However extreme furniture pieces often push the movers ingenuity to the extreme, and requires alot of experience do immediately know which precise &quot;furniture ballet&quot; is required. As a rule of thumb : if an object makes three points of contact with the wall/floor/ceiling, then the object cannot be pushed any further without causing damage to the surroudings. . To save money on moving: order a very large truck to make the loading and offloading easier, and pack as much as possible in regular cardboard boxes. As much as possible, all the irregular objects should be packing into boxes, and as many boxes as necessary. The client should dissessemble the furniture as much as possible beforehand. Otherwise the movers need to spend working hours on the assembly/disassembly of furniture, and or the preparation of more fragile objects. . Another difficulty is the patience and time required to safely move objects in tight spaces. For example, IKEA items are very popular. However IKEA distributes their furniture totally collapsed and optimized, while the consumer is required to read the instructions to reassemble into the stable furniture item. But movers might not be able to collapse the furniture item, and are sometimes even required to transport the item &quot;as is&quot;. For IKEA items, the assembled item as no strength, and was not at all designed for &quot;strongman&quot; transport (IKEA is heavy). . Now for all the complicated parameters that exist in moving, in this article our goal is to reduce everything to the simplest variables. Basically, if a client calls and wants to move their entire household, and wants to have an estimate (or the moving manager wants an estimate for their own schedule), then we ask the following questions: . When is the last time the client has moved their household? . | If appplicable, ask how long it took and how many &quot;human labour hours&quot; were required for their last move? . | How many &quot;bedrooms&quot; are now being moved? . | (Basic logistics: pickup and dropoff addresses). . | What kind of heavy items? (Fridges, couches, exercises equipment, etc.). . | We make some comments: If the client is only moving a select number of items, then ask client &quot;how did the item get here, how many persons were involved, how long did it take&quot;. . Question 1. gives a lower bound (&quot;a floor&quot;) for the moving manager. Our experience is that people only accumulate items, even more items, after they move. When persons are settled in a location, then they collect more and more diverse items. This always adds to the time required and increases the complexity. Question 2. gives some idea, for example was it a team of four movers or two? Was it a big truck, or a smaller cube truck? Were there any incidents during that last move, particular events or damages to the items? . Question 2. is applicable only if the client can remember the last time the item was moved. However it does help manage the clients expectations. . Question 3. is important, especially for single persons who have recently moved themselves. For every single person, there is required approximately 6 to 10 total labour hours required. I.e. two movers require approximately 3 to 5 hours to move a single person (bachelor). This is large interval, which really determines on the particular circumstances. Heavy objects can take 15 -- 30 minutes per item to move per team of two. . Questions 4, 5 are rather standard. Some estimate of the travel time and circumstances is necessary. For example, if the clients are located in an appartment building, then there is frequently a large walking distance required, and if there is an elevator involved, then the time can be much longer. . We also discuss the basic questions which are most useful for estimating the total cost of moving a household. This manages the client&#39;s expectations, but also allows the moving manager to maximize their profit and schedule themselves accordingly. .",
            "url": "https://jhmartel.github.io/fp/moving/delivery/economics/2022/04/05/Economics_Moving_Delivery.html",
            "relUrl": "/moving/delivery/economics/2022/04/05/Economics_Moving_Delivery.html",
            "date": " • Apr 5, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Six Design Principles for BoC's CBDC",
            "content": ". Disclaimer: the author is private citizen with zero affiliation with BoC. These brief articles are based on publically available documents and are completely speculative. . This article is brief. We simply enumerate six design principles which we believe are necessary for the BoC&#39;s CBDC. These principles are obviously necessary for the BoC to fulfill and satisfy it&#39;s own mandate and charter. Thus we propose the following six propositions need be satisfied by any proposal for BoC&#39;s CBDC. . (1) CBDC&#39;s must enable negative interest rates. (savings will be subject to time decay) . (2) CBDC&#39;s will be &quot;programmeable money&quot; (nonfungible) . (3) CBDC&#39;s will require static, hardcoded digital identities for the public. (strictly one wallet per person) . (4) CBDC must allow the BoC to exclusively control and monopolize monetary supply. (monetary supply, e.g. buying and selling treasury bonds is the central banks essential primary tool). . (5) BoC must require that only &quot;authorized participants&quot; are allowed to hold and trade base layer cryptocurrencies. (public prohibited from trading base tokens). . (6) The BoC&#39;s CBDC ledger will not be auditable to the public. (privacy is essential for security). . So we could implement the CBDC as smart constracts over a base layer, like Stellar (XLM) or Ripple (XRP) or Cardano (ADA). The smart contract would have strict conditions under which it&#39;s validator function returns true. These validators would need to depend on many &quot;world&quot; parameters, e.g. specific personal identity. That is, the validator would always need to refer to an outside centralized resource before validating the transaction. . End of article. . -JHM. .",
            "url": "https://jhmartel.github.io/fp/boc/cbdc/money/2022/03/26/6ixDesignPrinciplesOfBoCsCBDC.html",
            "relUrl": "/boc/cbdc/money/2022/03/26/6ixDesignPrinciplesOfBoCsCBDC.html",
            "date": " • Mar 26, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Radioactive Gold Remediation",
            "content": ". Disclaimer: The author is interested in commodities and precious metals, and is generally interested in scientific questions, especially about the mysteries of atomic structure and the recent evidence of Saffire-Aureon project of remediating nuclear waste. The subject of this brief article is to simply highlight that directly testing this possibility on gold and silver bullion would significant diminish the threat of radioactive contamination of precious metals vaults. . This is a brief article. Jim Rickards has remarked in some of his videos, and his book &quot;The New Case for Gold&quot; that gold bullion bars (silver included) are at risk of radioactive contamination. For example, if a palette of bullion bars had been previously exposed to radio activity, then they could perhaps unwittingly be introduced into the general bullion vault and contaminate all the specimens. Or perhaps some radioactive material is released intentionally by bad actors and contaminating the bars. This risk is addressed by a recent amendment of the Royal Canadian Mint in its ETR (exchange-traded receipts) program. Risk of Radioactive Gold is Uninsurable . Presumably there would be an issue in the exchange and transit of such contaminated bullion. The radioactive halflife could potentially be millions of years. . However the recent experimental work of the Safire-Aureon Project has indicated that exposing radioactive materials to $H^+$ ions actually increases the decay rate! In otherwords, the decay rate depends on the atoms relative to their environment. Basically, if the contaminated bars were directly exposed to the electrical plasma environment of Aureon&#39;s &quot;star-in-a-jar&quot;, then the radioactivity could be significantly accelerated. The question is: how many orders of magnitude can the decay-rate be accelerated? Can a million year decay rate be reduced to 1 day? What would be the energy required to maintain $H^+$ bombardment? . Many more details are required, and this is only preliminary. -JHM. .",
            "url": "https://jhmartel.github.io/fp/eu/saffire/gold/pollution/2022/03/25/Radioactive_Gold_Remediation.html",
            "relUrl": "/eu/saffire/gold/pollution/2022/03/25/Radioactive_Gold_Remediation.html",
            "date": " • Mar 25, 2022"
        }
        
    
  
    
  
    
        ,"post9": {
            "title": "Brief Remarks on Designing Bank of Canada's CBDC",
            "content": ". Here we collect some hypotheses regarding the design goals of BoC (Bank of Canada)&#39;s CBDC (central bank digital currency). The author has no priviledged &quot;insider&quot; information, but reasons from the point-of-view of a public citizen who is well-informed of open source documentation, e.g. BoC working-papers, keyword = &quot;digital&quot; . So it&#39;s evident that BoC is actively investigating CBDCs, e.g. Jasper. For better or worse, the digitization of all assets marches on. Therefore if BoC wants to further digitize the monetary functions of the Bank of Canada, then alot of questions arise. First I would have to ask Why?, What are the goals of the CBDC? . For it naively appears that electronic money has already been achieved via Interac cards and the debit payment system. So what is deficient in the current form of electronic money? What is the CBDC going to solve for the BoC? What is the valued added? What is the value added for the bank versus for the public and individual?. . The entry of institutional investment into cryptocurrencies has provoked a reaction from central banks, BIS, IMF, around the world, namely because crypto&#39;s are monetary competitors. In otherwords, the public is increasingly aware of digital options for exchanging their fiat dollars into other anti-inflationary (and often speculative) digital tokens. The market cap of cryptos being actively traded and held on exchanges continues to grow. [insert specific figures]. . So competition has entered, and the central banks are reacting. Presently BoC estimates that only 5 per cent of Canadians have BTC (this is surely an underestimate), so there appears to be relatively small demand for cryptocurrencies, and almost zero demand for central bank digital currencies. . A person might be willing to invest in digital yuan, say, in the prospect of that foreign currency being backed by hard money gold reserves. But any foreign holder of digital yuan (especially at this relatively early stage) is subject to a large amount of spam, and inquiries, and phishing emails. In otherwords, acquiring the digital yuan comes with a diminished privacy and/or anonymity. This is something of a liability to the foreign holder of digital yuan. . We observe that the central banks, and specifically BoC, are keen to distinguish their CBDC&#39;s from the general cryptocurrencies. I.e. it is strongly discouraged to conflate or equivocate &quot;CBDCs&quot; with &quot;cryptos&quot;. This has various motivations, e.g. branding and marketing to control public opinion, but it&#39;s also an important technical distinction, for the CBDC will be strongly centralized with the BoC. . How? . Let&#39;s comment on centralized versus decentralized currencies. The decentralization in crypto refers to various properties of the networks. First, it refers to the fact that transactions can be confirmed by any node that either solves the nonce problem (in PoW) or is randomly elected (where the random choice is decentrally chosen). . In BTC&#39;s original design, there was an anti-inflationary mechanism, namely in the &quot;halving&quot; principle and miner rewards. The miners expend the energy and invest in the IT infrastructure to send and receive and confirm transactions in the ledger, and in most cases, the miner&#39;s receive token rewards for these services. Eventually, I think it&#39;s approximately 2150 AD, the miners will not receive any BTC rewards, and there will be a strict fee structure. I don&#39;t think anybody has any idea whether this will sufficiently motivate miners to preserve the integrity of the ledger, i.e. it might become more profitable to destroy the record of the ledger. . There are differences between proof-of-work (like original BTC) or proof-of-stake (like ETH, or ADA). But the point is that tokens are issued as rewards for miners and nodes. The various cryptocurrencies have different governance policies for how tokens are distributed, to prevent monetary inflation. This is indeed one of the standard arguments in favour of BTC as &quot;perfect money&quot; (although we don&#39;t necessarily agree with Saylor, Keiser, Breedlove, et.al. that BTC is &quot;perfect&quot; money.) . The Bank Of Canada has a monopoly on printing currency (i.e. fiat dollar bills, or electronic money), and it&#39;s extremely unlikely that they will surrender this monopoly in their CBDC. (It&#39;s basically certain, since this monopoly is the exclusive right and foundation of BoC&#39;s mandate). This is one reason why BoC cannot allow cryptocurrencies to compete with BoC&#39;s dollar. If people flee the Canadian dollar, then the main tool and mandate of the BoC (control of monetary supply) is annulled. . So we can assume that the goal of the CBDC is to have tokens which can only be issued by the centralized authority of BoC. This suggests that BoC will either develop their own network for CBDC transactions (extremely unlikely, i think), or they will attempt to build their token on top of another pre-existing network. For example, the BoC&#39;s CBDC&#39;s might essentially be smart contracts on top of either Ripple (XRP) ledger or Stellar (XLM) ledger, or something else. For security purposes I would recommend ADA (Cardano). . This raises the question What will the form of the CBDC smart contracts take? Reading the central bank literature, from our open source public civilian position, it appears that the BoC desires a CBDC with the following properties. . (1) CBDC&#39;s must enable negative interest rates. . (c.f. IMF&#39;s &quot;Breaking the zero bound&quot;, and Finance Minister Mme. Freeland&#39;s comments on &quot;savings as preloaded stimulus&quot;). This is effected by adding a time-decay factor on savings. . (2) CBDC&#39;s will be &quot;programmeable money&quot;, i.e. the CBDC will be nonfungible. . If the CBDC seeks maximal control, then purchases would be validated depending on the parameters (PersonalID, VendorID, ItemID, Price. The PersonalID will have an associated &quot;clearance&quot; or &quot;allowance&quot; of goods and services. These clearances/allowances are like digital permissions, saying &quot;This Person X is permitted to purchase Item Y from vendor Z at this time and date and location at this price up to this amount&quot;. . (3) CBDC&#39;s will require static, hardcoded digital identities for the public. . In otherwords, the pseudo-anonymity of general cryptocurrencies will be replaced with total disclosure of the users to the centralized authority. E.g., if dollar bills always had GPS and PersonalID embedded which exclusively is updated and permissioned by a centralized authority. Moreover the total history of the bill would be recorded in a ledger. . Cryptocurrencies (in general) can function with pseudo-anonymous addresses and multiple wallets for users. However the CBDC can only function with hard-coded digital identity for all public users. . (4) CBDC must allow the BoC to directly control and monopolize monetary supply. . So we must examine how the BoC will maintain CBDC supply and the &quot;fiat price&quot; of the CBDC on the chains. In principle, there exists nearly zero cost for the BoC to issue new money, i.e. they &quot;print&quot; money (brrrrr) either with electronic entries or by increasing the physical printed money supply (at some fixed cost). . Moreover, there is another issue. If the CBDC is a contract on top of, say, the Ripple ledger, then what prevents users from bypassing the BoC CBDC and directly acquiring XRP tokens? For the XRP tokens will be &quot;harder money&quot; and more functional than the CBDC, and there will be a flow from CBDC to XRP via Gresham&#39;s Law. This will require some law or federal emergency mandate that . (5) BoC must require that only authorized participants will be allowed to hold and trade base layer cryptocurrencies. . And indeed this is a trend observed around the world. . There&#39;s more to say, but I&#39;ll keep it short for now. . JHM. .",
            "url": "https://jhmartel.github.io/fp/money/boc/cbdc/2022/03/24/CBDC_Opinion.html",
            "relUrl": "/money/boc/cbdc/2022/03/24/CBDC_Opinion.html",
            "date": " • Mar 24, 2022"
        }
        
    
  
    
  
    
  
    
  
    
        ,"post13": {
            "title": "Closing Steinberg, Part 1. Mapping Class Group",
            "content": "We present the formal definition of Closing Steinberg symbols. . Let $ Gamma$ be a group acting on a space $X$ by group action $X times Gamma to X$. If $P subset X$ is a subset of $X$, then a finite subset $I$ of $ Gamma$ is said to formally close $P$ if the iterated symmetric difference of $ { gamma. P ~|~ gamma in I }$ vanishes (equal to empty set $ emptyset$). . N.B. The vanishing of the iterated symmetric difference means the chain sum $ gamma.P$, for $ gamma in I$, vanishes over mod 2 coefficients. I.e. every element in the $I$-translates of $P$ occurs an even number of times. . The above is the abstract formulation of a problem we call Closing the Steinberg symbol. In our applications the subset $P$ is a panel representing the convex hull of a sphere at infinity which is called the &quot;Steinberg symbol&quot;. . Now the key to Closing Steinberg (CS) is to find nontrivial formal solutions. We will illustrate with the specific group $ Gamma = Mod(S)$ which is the mapping class group of a compact hyperbolic surface $S$. We will begin with genus $g(S)=2$. . Now we introduce the basic functions using Mark C. Bell&#39;s curver: . Now we make the basic definitions of the reference pant, and the mapping class elements $ zeta, nu, mu$. . pant={a,b,c} ## pant={a,b,c} is the standard pant. zeta=a*e*c*f*b ## zeta is the order 6 element in MCG arising from chain relation. ## nu=a*e*c*f ## nu is order 10 element in MCG mu=nu**4 ## mu is order 5 element in MCG. . We define $ xi$ as the union of the standard pair of pants with its $ mu$-translate. The $ mu$-translate of $ {a,b,c }$ is a pair of pants dual to $ {a,b,c }$. . The mapping class element $ mu$ is an order 5 element in $Mod(S_2)$. We propose that the powers of $ mu$, namely $I= {Id, mu, mu^2, mu^3, mu^4 }$, formally close the symbol $ xi$. This solution will be nontrivial because we will establish that $ mu^i xi = mu^j xi$ if and only if $i=j$. Thus the $I$-translates of $ xi$ are distinct, while the chain sum $ sum_{i=0}^4 mu^i xi$ vanishes over ${ bf{Z}}/2$ coefficient. . ## xi is obtained by joining the initial pant p with its mu translate. xi=pant|Translate(mu, pant) ## important to verify that pant and the mu-translate are disjoint. ## Ad(mu,pant) is &quot;opposite pair of pants&quot; print(&quot;The mu translate of the standard pant is disjoint from pant. &quot;, pant &amp; Translate(mu, pant) == set()) print() M0=xi M1=Translate(mu,xi) M2=Translate(mu**2,xi) M3=Translate(mu**3,xi) M4=Translate(mu**4,xi) ## The following proves that all the symbol translates are nontrivial, and there is no complete coincidence ## between the translated symbols. print(&quot;The mu translates of xi are all pairwise distinct:&quot;, M0!=M1 and M0!=M2 and M0!=M3 and M0!=M4 and M1!=M2 and M1!=M3 and M1!=M4 and M2!=M3 and M2!=M4 and M3!=M4 ) print() ## The following proves that the total chain sum of the translated symbols vanishes mod 2. ## I.e. the iterated symmetric difference of the translated symbols is equal to empty set. print(&quot;The iterated symmetric difference of the mu translates is empty.&quot;, ((((M0^M1))^M2)^M3)^M4 ==set()) print() print(&quot;The mu-orbit of xi is supported on ten curves.&quot;, 10==len(M0|M1|M2|M3|M4) ) print() print(&quot;Therefore we find I={Id, mu, mu**2, mu**3, mu**4} is a formal solution to Closing the Steinberg symbol xi in genus two.&quot;) print(&quot;&quot;) . The mu translate of the standard pant is disjoint from pant. True The mu translates of xi are all pairwise distinct: True The iterated symmetric difference of the mu translates is empty. True The mu-orbit of xi is supported on ten curves. True Therefore we find I={Id, mu, mu**2, mu**3, mu**4} is a formal solution to Closing the Steinberg symbol xi in genus two. . So we have found a formal solution $I$ to CS. For applications we need further verify that $I$ satisfies further geometric properties. Specifically we need establish: . the $I$-translates of $ xi$ have a well-defined convex hull $F:=conv(I. xi)$ in $Teich(S)$. | the $ Gamma$-translates of $F$ generate a chain sum $ underline{F}:= sum_{ gamma in Gamma} gamma.F$ with well separated gates equal to the $ Gamma$-translates of $ xi$. | . Informally the idea is that $ xi$ represents a &quot;panel&quot; $P$, and $I$ closes the panel in the sense that the $I$-translates of the panel assemble to a closed ball. (Similar to how the (triangular, hexagonal) panels of a soccer ball assemble to form the closed ball). . But we must further study the $ Gamma$-translates of the ball itself, i.e. of the convex hull $F$. Most important for our setting is that the intersections of the various translates $ gamma F cap gamma&#39; F$ have a &quot;standard form&quot;, namely isometric to $ xi$ (the panel $P$). . Remark. It&#39;s not clear whether the above verification of ``well-separated gates&quot; can be performed in curver. While we are capable of considering the $ Gamma$ action on the elements of $I. xi$, we cannot necessarily compute the intersections $F cap gamma F$. The issue is that $F cap gamma F$ can intersect &quot;at-infinity&quot; (i.e. be asymptotic) without the convex hulls having an intersection in the interior of $Teich(S)$. Formally the solutions to CS solve a problem at infinity, but the next step is to study the solutions in the interior, and this becomes more geometric. .",
            "url": "https://jhmartel.github.io/fp/closing%20steinberg/curver/mcg/2022/02/28/ClosingSteinberg_Intro.html",
            "relUrl": "/closing%20steinberg/curver/mcg/2022/02/28/ClosingSteinberg_Intro.html",
            "date": " • Feb 28, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "Positronium Part I.",
            "content": ". Today we begin the study of Weber&#39;s potential in the isolated two-body system consisting of an electron and positron pair $e^-$ and $e^+$. We assume the particles $e^ pm$ have equal mass $m=m_{e^{ pm}}$. The reduced mass is concentrated at the centre-of-mass $ mu=m/2$. . Weber&#39;s force is attractive between the pair $e^ pm$ at all distances. . The particles $e^ pm$ do not indefinitely spiral inwards. Simulations indicate that the radial distance between $e^ pm$ stays strictly bounded between two upper and lower limits $$0 &lt; r_{lower} leq r leq r_{upper} &lt; + infty .$$ This is rigorously proved in Weber-Clemente, 1990.pdf). . If the electron is indivisible particle, then the above two-body problem models a pair $e^-$ and $e^+$ of isolated electron and positron. . But do the particles $e^ pm$ ever &#39;collide&#39; and annihalate? . In the standard physics textbooks, it seems well known that annihalation between $e^ pm$ occurs and two gamma rays are ejected in opposite directions when $e^ pm$. conserving momentum, etc., and converting all their mass into energy. Thus it&#39;s determined that two gamma rays of energy $0.511 keV$ are released, where Einstein&#39;s formula $E=m_ec^2$ is applied, where $m_e$ is the reduced mass. [ref] The annihalation of $e^ pm$ is apparently an experimental test of the validity of Einstein&#39;s &quot;mass-energy&quot; hypothesis. . But what does Weber&#39;s potential say about the annihalation of $e^+$ and $e^-$ ? . If we know the centre of mass has zero net force, then we can replace the positions $r_1$, $r_2$ of the particles by their relative distance $r_{12}$ from the centre of mass. This yields $$r_1=R + frac{m_2}{m_1+m_2} r_{12}$$ and $$r_2=R - frac{m_1}{m_1+m_2} r_{12}.$$ . Applying Newton&#39;s Second Law that $F_{21}=-F_{12}$ yields the following equation for $r_{12}&#39;&#39;$: $$ mu . r_{12}&#39;&#39; = F_{21},$$ where $ mu$ is the reduced mass of the system, namely $ mu= frac{m_1 m_2}{m_1+m_2}=0.5$. . In the following equations we use numpy.odeint to solve Weber equations of motion of the relative distance $r_{12}$. Therefore we have reduced the two-body problem to a one-body problem. This is a standard reduction. . Given the solution for $r_{12}$, how do we reconstruct the paths/positions of the particles $r_1$, $r_2$ ? Answer: via the relation $r_1=R+ frac{m_2}{m_1+m_2} r_{12}$ and $r_2=R- frac{m_1}{m_1 + m_2}r_{12}$. . Now the relative distance $r_{12}$ is a type of radial distance, and if $r, omega$ is spherical coordinates, then we have $$r&#39;^2=|v|^2= x&#39;^2+y&#39;^2+z&#39;^2=(r&#39;)^2+r^2 ( theta&#39;)^2. $$ The above formula is the usual $|v|^2=v_r^2+v_t^2$, and the tangent velocity $v_t$ satisfies $v_t=r theta&#39;$, where $ theta&#39;$ is the angular velocity. . The conservation of angular momentum says that the angular moment $L= mu r times v$, where $v$ is the linear velocity of $r$, is constant along the motion. Moreover one has $$|L|= mu r^2 theta&#39;.$$ Thus we find the formula $$ theta&#39;= frac{|L|}{ mu r^2}.$$ This implies $$T= frac{ mu}{2}v^2= frac{ mu}{2}[(r&#39;)^2+ frac{|r times v|^2}{r^{2}}]$$ represents the kinetic energy of the system. . The conservation of energy says $T+U$ is constant along trajectories. . # Here we define basic functions. def cross(v1, v2): x1, y1, z1 = v1 x2, y2, z2 = v2 return [y1*z2 - z1*y2, -(x1*z2 - z1*x2), x1*y2 - y1*x2 ] def rho(rel_position): x,y,z = rel_position return (x*x+y*y+z*z)**0.5 def dot(vector1, vector2): x1, y1, z1 = vector1 x2, y2, z2 = vector2 return x1*x2+y1*y2+z1*z2 def rdot(position, vector): return dot(position, vector)/rho(position) def norm(rel_velocity): return rho(rel_velocity) mu=0.5 ## reduced mass of the system. We assume m1 and m2 are equal, hence mu=1/2. c=1.0 ## speed of light constant in Weber&#39;s potential # Define the angular momentum def AngMom(rel_position, rel_velocity): return cross(rel_position, rel_velocity) def L(rel_position, rel_velocity): return norm(cross(rel_position, rel_velocity)) # Linear Kinetic Energy def T(rel_position, rel_velocity): vt = norm(cross(rel_position, rel_velocity)) # next formula decomposes v^2=(vr)^2+(vt)^2, where vt=r*θ&#39;=|L|/(mu*r) return (mu/2)*(rdot(rel_position, rel_velocity)**2) + (mu/2)*(rho(rel_position)**-2)*(vt**2) ## Weber Potential Energy ## Negative sign given -1=q1*q2 def U(rel_position, rel_velocity): x,y,z = rel_position vx,vy,vz = rel_velocity rdot=dot(rel_position, rel_velocity)/rho(rel_position) return -(1/rho(rel_position))*(1-(rdot*rdot)/2) . . import numpy as np from scipy.integrate import odeint, solve_ivp import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D ## Integrating two-body isolated system of oppositely charged particles ## i.e. positron+electron pair. ## The product of the charges q1*q2 is factor in Weber&#39;s force law, and appears twice ## in the formula of Newton&#39;s F=ma. def weber(t, rel_state): x, y, z, vx, vy, vz = rel_state r=(x*x + y*y + z*z)**0.5 rdot=(x*vx+y*vy+z*vz)/r A=(-1)*r**-2 ## minus sign from q1*q2 B=1-(rdot*rdot)/2 C=(mu+((c*c*r)**-1))**-1 ## +plus instead of -minus. dxdt = vx dydt = vy dzdt = vz dvxdt = (x/r)*A*B*C dvydt = (y/r)*A*B*C dvzdt = (z/r)*A*B*C return [dxdt, dydt, dzdt, dvxdt, dvydt, dvzdt] t_span = (0.0, 100.0) t = np.arange(0.0, 100.0, 0.1) y1=[2.0,0,0,] # initial relative position v1=[-0.4, 0.4, 0] # initial relative velocity result = odeint(weber, y1+v1, t, tfirst=True) #here odeint solves the weber equations of motion relative y1+v1 for t. Energy=T(y1,v1) + U(y1,v1) print(&#39;The initial total energy T+U is equal to:&#39;, Energy) print(&#39;The initial angular momentum is equal to&#39;, norm(AngMom(y1,v1))) fig = plt.figure() ax = fig.add_subplot(1, 2, 1, projection=&#39;3d&#39;) ax.plot(result[:, 0], result[:, 1], result[:, 2]) ax.set_title(&quot;position&quot;) ax = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ax.plot(result[:, 3], result[:, 4], result[:, 5]) ax.set_title(&quot;velocity&quot;) . The initial total energy T+U is equal to: -0.37999999999999995 The initial angular momentum is equal to 0.8 . Text(0.5, 0.92, &#39;velocity&#39;) . What does the above plot demonstrate? . It reveals a precession motion around the centre of mass. This is not predicted by Coulomb&#39;s force, which bounds the trajectories to elliptical orbits like Newton&#39;s Law of Gravitation. . The force is central, therefore we have conservation of angular momentum, and implies the system is constrained to a plane, namely orthogonal to the angular moment of the system. . Moreover the system satisfies a conservation of linear momentum, namely the sum $T+U$ is constant. . Problem: Verify Assis-Clemente&#39;s 1990 formula for the lower and upper limits of the relative distance along the orbits. | . import matplotlib.pyplot import pylab r_list=[] for j in range(1000): sample_position=[result[j,0], result[j,1], result[j,2]] sample_velocity=[result[j,3], result[j,4], result[j,5]] r_list.append( ( int(j), rho(sample_position) ) ) prelistr = list(zip(*r_list)) pylab.scatter(list(prelistr[0]),list(prelistr[1])) pylab.xlabel(&#39;time&#39;) pylab.ylabel(&#39;rho&#39;) pylab.title(&#39;Solutions have Upper and Lower Limits&#39;) pylab.show() #TU_list=[] #for j in range(1000): # sample_position=[result[j,0], result[j,1], result[j,2]] # sample_velocity=[result[j,3], result[j,4], result[j,5]] # TU_list.append( # (rho(sample_position),T(sample_position,sample_velocity)+U(sample_position, sample_velocity))) #prelist1 = list(zip(*TU_list)) #pylab.scatter(list(prelist1[0]),list(prelist1[1])) #pylab.xlabel(&#39;distance r&#39;) #pylab.ylabel(&#39;T+U&#39;) #pylab.title(&#39;&#39;) #pylab.show() # The plot below demonstrates the conservation of angular momentum. # Note that rdot is directly equal to the sample_velocity. I.e. there is # no need to define rdot=v.hatr/r. This was error. #A_list=[] #for j in range(1000): # sample_position=[result[j,0], result[j,1], result[j,2]] # sample_velocity=[result[j,3], result[j,4], result[j,5]] # A_list.append( # (rho(sample_position), norm(cross(sample_position, sample_velocity)) ) ) #prelist2 = list(zip(*A_list)) #pylab.scatter(list(prelist2[0]),list(prelist2[1])) #pylab.xlabel(&#39;rho&#39;) #pylab.ylabel(&#39;Angular Momentum&#39;) #pylab.title(&#39;Conservation of Angular Momentum&#39;) #pylab.show() #rho_list=[] #for j in range(180): # rho_list.append( # (int(j), rho([result[j,0], result[j,1], result[j,2]]), # ) # ) . . from sympy import * t=symbols(&#39;t&#39;) m=symbols(&#39;m&#39;) c=symbols(&#39;c&#39;) r=Function(&#39;r&#39;)(t) P=Function(&#39;P&#39;)(r,t) F=Function(&#39;F&#39;)(r,t) U=-(r**-1)*(1-((r.diff(t))**2)*(2*c*c)**-1) F=(-1)*(U.diff(t))*((r.diff(t))**-1) pprint(simplify(U)) print() pprint(simplify(F)) ## symbolic computation of the Force law. . . 2 ⎛d ⎞ ⎜──(r(t))⎟ 2 ⎝dt ⎠ - c + ─────────── 2 ────────────────── 2 c ⋅r(t) 2 ⎛d ⎞ 2 ⎜──(r(t))⎟ 2 d ⎝dt ⎠ - c - r(t)⋅───(r(t)) + ─────────── 2 2 dt ─────────────────────────────────── 2 2 c ⋅r (t) .",
            "url": "https://jhmartel.github.io/fp/weber/positronium/two-body/2022/02/22/Positronium_Part1.html",
            "relUrl": "/weber/positronium/two-body/2022/02/22/Positronium_Part1.html",
            "date": " • Feb 22, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "One-Dimensional Ampere Force",
            "content": ". One-Dimensional Ampere . We continue with our discussion of Ampere&#39;s force, and consider the special case where the current elements are all pairwise parallel and colinear. In otherwords we assume the current elements belong the a line $ ell$ in $ bf{R}^3$. For simplicity we consider the current elements belonging to the $z$-axis. . The state of a current element on the $z$-axis is then represented by a real-valued function $v(x)$ representing the velocity of the current element. Likewise we interpret $|v(x)|$ as the intensity of the current element. Ampere&#39;s force law in the one-dimensional case then becomes: . $$F_{y ~ text{on}~x} =|v(x)|~|v(y)|~v(x)~v(y) ~ nabla_1 ( frac{1}{r}) . $$ . If we integrate the force $F$ over the entire line we obtain $$F_{ text{current on}~ x} = |v(x)|~ v(x) ~[ nabla_1 cdot int dy~ frac{|v(y)| v(y)}{x-y} ]. $$ . The hypothesis of the force being balanced on the line is equivalent to the vanishing $$ nabla_1 ~ int dy frac{|v(y)|~ v(y)}{x-y}= frac{d}{dx} ~ int dy frac{|v(y)|~ v(y)}{x-y}=0 .$$ Equivalently, the force is balanced if the integral $$H(v)(x)=h(x):= int_{- infty}^{+ infty} dy~ frac{|v(y)|~ v(y)}{x-y} $$ is a constant function of $x$ wherever $v(x) neq 0$. . N.B. The integral defining $H(v)$ is taken over the entire real line. We observe that there is no absolute value sign on the denominator $x-y$. This is to include the direction of $ hat{r}$ in the original Ampere law. . Our definition of $H$ is Hilbert&#39;s singular integral transform for real-valued functions. Strictly speaking, the singular integral does not always integrate to a finite number. In the literature, the integral is frequently replaced with a Cauchy principal value. This is related to the function $ frac{1}{y}$ being not absolutely integrable on the real line. However there is sufficient cancellation in the integral to obtain a well-defined principal value. . If the current $v$ is everywhere constant, then symmetry shows the integral $H(v)$ is identically zero, and therefore the total force $F$ of the current is everywhere zero. Therefore we find $v=constant$ is a solution to the balance equation. . N.B. Most discussion of the Hilbert transform is restricted to square-integrable functions on the line $L^2( bf{R})$. On $L^2$ one finds the Hilbert transform defines a unitary operator and is an anti-involution, satisfying $H circ H=-Id$. However the only $L^2$ constant function is the zero function. . Question: Are there any time-independant solutions to the balance equation, i.e. does there exist nonconstant $v in L^ infty( bf{R})$ with $H(v)$ constant? . Question: Can we find time-dependant solutions to the balance equation? I.e. find functions $v_t in L^ infty$ such that $H(v_t)$ is constant for all time $t$. . Remark. The Hilbert transform (modulo homothety) is the only singular operator in one-dimensions which commutes with the affine translation and affine dilatation. This corresponds to the Ampere force commuting with the affine change of variables $x mapsto ax+b$. Since Ampere&#39;s force is relational, it seems proper that the corresponding Hilbert transform also possess these same properties. . Remark. It appears that the only Borel-Radon measures $ mu$ on the real line $ bf{R}$ which have a constant Hilbert transform $H( mu)=c$ are the uniform measures $ mu=const.dy$. If this remains true, then we identify the kernel of $H circ H$ with the uniform measures on $ bf{R}$. .",
            "url": "https://jhmartel.github.io/fp/fastpages/jupyter/2022/02/18/One_Dimensional_Ampere.html",
            "relUrl": "/fastpages/jupyter/2022/02/18/One_Dimensional_Ampere.html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "Weber's Critical Radius, Work, and E=mc2 Formulas",
            "content": ". In the [previous post] we discussed the equations of motion of a charged particle in free fall w.r.t. Weber&#39;s potential $U$. Now we consider the problem of work, and the problem of moving particles &quot;upstream&quot; of the potential. . Recall the Coulomb-type expression that &quot;opposite charges attract&quot; and &quot;like charges repel&quot;. If we arranged some charged particles on a plate, then in a short time these particles would either be repelled outwards to the boundary of the plate or the opposite charges would cancel on the interior. Again this is with respect to the Coulomb model $V(r)=1/r$. . But Weber&#39;s model has the following amazing prediction: &quot;opposite charges attract except at a small critical distance $r=r_c$ where the charges acquires a negative inertial mass and the Weber force becomes repulsive&quot;. Furthermore, &quot;like charges repel except at a small critical distance where the Weber force becomes attractive&quot;. This latter prediction leads to Weber&#39;s *planetary model of the atom&quot;. [Insert ref]. . In the (cgs) units the critical radius $r_c$ is computed as $r_c= frac{1}{m c^2}$ where $m$ is the relative inertial mass of one of the particles. The proof of this formula is an application of Newton&#39;s second law, that $m a = bf{F}$ where $ bf{F}$ is Weber&#39;s force. [insert ref] . Now the question arises: if we have two identical but opposite electrically charged particles, say $(-1)e$ and $(+1)e$, where $e$ is a small mass, then how much work is required to drive $(-1)e$ and $(+1)e$ to within Weber&#39;s critical radius $r_c$? . Weber comments in his final memoir [ref] that an infinite amount of work would be required, however no technical details are provided. In fact this author thinks its evident that a large finite amount of work is required, and the computation of this work required is the subject of this post. . How to compute Work: We imagine a particle moving through a potential $U$ along a trajectory $ gamma.$ Our goal is to determine how much work is required to breach (&quot;pass through&quot;) the critical radius $r_c= frac{1}{mc^2}$ in units where $4 pi epsilon_0 = 1$. . We begin assuming the particle&#39;s trajectory is rectilinear. This means the tangent $ gamma&#39;$ and $ gamma$ are parallel for all values of the parameter. Moreover we can use the Riemannian idea of parameterizing the curve by arclength. Then we ask how much work is required to move the particle through $U$ at a constant rate of speed, namely $|| gamma&#39;||=1$. . Weber&#39;s force is conservative, so there is some path independance, however the terminal conditions are not fixed a priori. It might happen that breaching the Weber radius is easier if the particles velocity is nearly parallel to the &quot;virtual&quot; surface of the Weber&#39;s critical radius. That is to say, the curvature term $r r&#39;&#39;/c^2$ in Weber&#39;s force law might sometimes reduce the work needed, depending on the sign. . In terms of the relational variables recall the useful formula/definition $$ r&#39; = frac{ bf{r} cdot bf{r&#39;}}{r}.$$ In our setting we find $$r&#39;= frac{ gamma cdot gamma&#39;}{|| gamma||}.$$ Applying the Cauchy-Schwartz inequality, we find $$r&#39;=1.$$ I.e. equality is obtained in Cauchy-Schwartz because $ gamma, gamma&#39;$ are parallel by hypothesis and $|| gamma&#39;||=1$. . Moreover the rectilinear motion implies $r&#39;&#39;=0$, i.e. the trajectory has zero curvature, since the direction of the particle does not change. Therefore Weber&#39;s force leads to work being computed by the integral $$W=(1- frac{1}{2c^2}) int_{+ infty}^{r_c} frac{1}{r^2} dr = (1- frac{1}{2c^2})mc^2=mc^2-m/2.$$ So what is the total energy of the above system? The total energy is the work required $mc^2 - m/2$ plus the initial kinetic energy $T_i=m| gamma&#39;|^2/2=m/2$. Therefore the total energy required to breach the Weber critical radius is $E=W+T_i=mc^2$. . N.B. All the while our particles are &quot;travelling upstream&quot;. So the above computation indicates that if a particle is given sufficient energy (i.e. sufficient kinetic energy, then the particle could breach the Weber critical radius, and arriving at the Weber radius with almost zero kinetic energy). . N.B. The integral representing $W$ is parameterization independant. Therefore the work required by the unit-parameterized path is not overly specialized, but represents the general computation. . The above discussion was restricted to rectilinear trajectories. But the possibility remains that curvilinear (&quot;spiralling&quot;) trajectories require less work to breach the Weber radius. Thus while it appears that breaching the Weber radius via rectilinear paths requires large energy $ approx mc^2$, perhaps the spiralling paths -- where the curvature term maintains a definite sign -- are the more interesting. . Problem: Determine the minimum energy required for an isolated two-body system to breach the Weber critical radius. . Answer: The minimum energy required to breach the critical radius is $E=mc^2$. . This is consequence of the fact that $ bf{F}$ is a conservative force, therefore dependant only on the initial and terminal states, and not the path taken. Moreover the work done by a particle traversing a path $ gamma$ depends only on the difference in potential energies. This implies that the above evaluation in the rectilinear case is essentially the same for all paths from some initial point to to within the critical radius. . Is the energy spectrum within the critical radius continuous? (Yes, i think the orbits can have arbitrary energy within the radius). | How to relate Birkeland currents (FFAC) to Weber&#39;s potential? Don Scott considers the plasma cylinder, with a stead current. Then the min energy state has zero internal pressure, therefore the net internal energy of the plasma cylinder needs be minimized, i.e. vanishing. Difficulty: without the Maxwell equations we do not know relationship between the current flow $I d ell=qdv$. This equality is Weber&#39;s hypothesis, i.e. a current flow is equivalent to a charge in motion, where $dv$ represents the instantaneous velocity of the charged particle. |",
            "url": "https://jhmartel.github.io/fp/fastpages/jupyter/2022/02/16/WeberEMC2.html",
            "relUrl": "/fastpages/jupyter/2022/02/16/WeberEMC2.html",
            "date": " • Feb 16, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "Phipp's Potential",
            "content": "Here we examine Phipp&#39;s potential $P= frac{1}{r} sqrt{1- frac{r&#39;}{c}}$. It&#39;s clear that Phipp&#39;s potential imposes an upper bound on the velocities of particles in free fall relative to $P$. But while Phipp&#39;s potential guarantees subluminal velocities, it does not appear to satisfy a conservation of energy, and the quantity $T+P$ is not constant along trajectories. . The Phipp potential can induce negative effective mass at small distances, similar to the case of Weber&#39;s potential. However the critical radius depends on the relative velocity of the particles. By contrast Weber&#39;s critical radius depends only on the mass $m$ and $c^2$. . These two facts are demonstrated in the cells below, and demonstrates some severe disadvantages to Phipp&#39;s potential. We are therefore inclined to investigate Weber&#39;s potential as a model of electrodynamics. . from sympy import * t=symbols(&#39;t&#39;) m=symbols(&#39;m&#39;) c=symbols(&#39;c&#39;) r=Function(&#39;r&#39;)(t) P=Function(&#39;P&#39;)(r,t) F=Function(&#39;F&#39;)(r,t) P=(r**-1)*sqrt(1-r.diff(t)/c) F=(-1)*(P.diff(t))*((r.diff(t))**-1) pprint(simplify(P)) print() pprint(simplify(F)) ## symbolic computation of the Force law. . ______________ ╱ d ╱ c - ──(r(t)) ╱ dt ╱ ──────────── ╲╱ c ──────────────────── r(t) 2 d r(t)⋅───(r(t)) 2 ⎛ d ⎞ d dt ⎜c - ──(r(t))⎟⋅──(r(t)) + ────────────── ⎝ dt ⎠ dt 2 ──────────────────────────────────────── ______________ ╱ d ╱ c - ──(r(t)) ╱ dt 2 d c⋅ ╱ ──────────── ⋅r (t)⋅──(r(t)) ╲╱ c dt . import numpy as np from scipy.integrate import odeint, solve_ivp import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D m=0.5 ## mass of second test particle c=1.0 ## speed of light constant in Weber&#39;s potential ## Kinetic Energy: we use the naive expression for vis viva. Is it correct? def T(vx, vy, vz): return m*(vx*vx+vy*vy+vz*vz)/2 ## Phipp&#39;s Potential Energy def P(x,y,z,vx,vy,vz): r=(x*x + y*y + z*z)**0.5 rdot=(x*vx+y*vy+z*vz)/r return (r**-1)*(1-rdot/c)**0.5 ## Integrating equations of motion relative Phipp&#39;s Force Law. def phipp(t, state): x, y, z, vx, vy, vz = state r=(x*x + y*y + z*z)**0.5 rdot=(x*vx+y*vy+z*vz)/r A=r**-2 B=(1-rdot)**0.5 C=(m- ( 2*r*rdot*((1-rdot)**0.5) )**-1 )**-1 dxdt = vx dydt = vy dzdt = vz dvxdt = (x/r)*A*B*C dvydt = (y/r)*A*B*C dvzdt = (z/r)*A*B*C return [dxdt, dydt, dzdt, dvxdt, dvydt, dvzdt] t_span = (0.0, 1000.0) t = np.arange(0.0, 1000.0, 0.001) y0=[10, 0.3, 0, -0.2, -0.9, .1] ## initial state of the system y0=[x, y, z, vx, vy, vz] result = odeint(phipp, y0, t, tfirst=True) Energy=T(y0[3], y0[4], y0[5] ) + P(y0[0],y0[1],y0[2],y0[3],y0[4],y0[5]) print(&#39;The initial total energy T+P is equal to:&#39;, Energy) print(&#39;The luminal energy is:&#39;, m*c*c/2) print(&#39;The energy is subliminal:&#39;, Energy &lt; m*c**2 /2) r = ( y0[0]*y0[0] + y0[1]*y0[1] + y0[2]*y0[2])**0.5 rdot = ( y0[0]*y0[3] + y0[1]*y0[4] + y0[2]*y0[5] ) /r print(&#39;Phipp`s critical radius is equal to:&#39;,(m- ( 2*r*rdot*((1-rdot)**0.5) )**-1)**-1) ## N.B. Phipp&#39;s critical radius depends on the distance and velocity! print(&#39;The initial radius r and velocity r` is within Phipp`s critical distance:&#39;, r &lt; (m*c*c)**-1 ) fig = plt.figure() ax = fig.add_subplot(1, 2, 1, projection=&#39;3d&#39;) ax.plot(result[:, 0], result[:, 1], result[:, 2]) ax.set_title(&quot;position&quot;) ax = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ax.plot(result[:, 3], result[:, 4], result[:, 5]) ax.set_title(&quot;velocity&quot;) . The initial total energy T+P is equal to: 0.3257156133373373 The luminal energy is: 0.25 The energy is subliminal: False Phipp`s critical radius is equal to: 1.4309087883533131 The initial radius r and velocity r` is within Phipp`s critical distance: False . Text(0.5, 0.92, &#39;velocity&#39;) . import matplotlib.pyplot import pylab def rho(x,y,z): return (x*x+y*y+z*z)**0.5 v_list=[] for j in range(4000): v_list.append( (rho(result[j,0], result[j,1], result[j,2]), T(result[j,3], result[j,4], result[j,5])) ) P_list=[] for j in range(4000): P_list.append( (rho(result[j,0], result[j,1], result[j,2]), P(result[j,0],result[j,1],result[j,2],result[j,3],result[j,4],result[j,5])+T(result[j,3], result[j,4], result[j,5])) ) prelist1 = list(zip(*v_list)) pylab.scatter(list(prelist1[0]),list(prelist1[1])) pylab.show() prelist2 = list(zip(*P_list)) pylab.scatter(list(prelist2[0]),list(prelist2[1])) pylab.show() .",
            "url": "https://jhmartel.github.io/fp/fastpages/jupyter/2022/02/11/PhippPotential.html",
            "relUrl": "/fastpages/jupyter/2022/02/11/PhippPotential.html",
            "date": " • Feb 11, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "Letter To Prof. Assis.",
            "content": "2022-02-10-Verifying Conservation of Energy with Python. . Dear Professor Assis, . I am currently studying the Weber potential $U= frac{e_1 e_2}{r} (1- frac{r&#39;^2}{2c^2})$ in python, and specifically looking at the equations of motion of an isolated two-body system. For computation i have chosen one particle to be the origin, and look to solve the equations of motion for the second particle. In computations I take $e_1=e_2=1$ and $c=1$, and the relative mass of the second particle to be $m=0.5$. (Is that mass to small?) . I am fairly confident that I have correctly integrated the equations of motion using python&#39;s odeint. . However I am not able to satisfactorily verify conservation of energy $d(T+U)=0$ along the trajectories, and I am not confident that I have the correct expression for kinetic energy $T$, i use the naive expression $T=mv^2/2$, where $v^2$ is computed in usual way as sum of squares of the velocities of the second particle of mass $m=0.5$. When I use the above expression for $T$ I find the sum $T+U$ is not constant along solutions to the equations of motion $mr&#39;&#39;=ma=F$, where $F=- hat{r} frac{dU}{dr}$ is Weber&#39;s force. . From your book on &quot;Relational Mechanics&quot; i understand that kinetic energy is more properly defined as the interaction energy of the particle with the stars at infinity. But is the naive kinetic energy $T=mv^2/2$ the correct expression for the isolated two-body system? . import numpy as np from scipy.integrate import odeint, solve_ivp import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D m=0.5 ## mass of second test particle c=1.0 ## speed of light constant in Weber&#39;s potential ## Kinetic Energy: we use the naive expression for vis viva. Is it correct? def T(vx, vy, vz): return m*(vx*vx+vy*vy+vz*vz)/2 ## Weber Potential Energy def U(x,y,z,vx,vy,vz): r=(x*x + y*y + z*z)**0.5 rdot=(x*vx+y*vy+z*vz)/r return (r**-1)*(1-(rdot**2)/2) ## Integrating equations of motion relative Weber&#39;s Force Law. ## I think I have implemented everything correctly. The formula for rdot is from Relational Mechanics, pp.168 ## but perhaps I have the wrong formula for r&#39;&#39; and have not applied Newtons second law F=mr&#39;&#39; correctly? def weber(t, state): x, y, z, vx, vy, vz = state r=(x*x + y*y + z*z)**0.5 rdot=(x*vx+y*vy+z*vz)/r A=r**-2 B=1-(rdot*rdot)/2 C=(m-((c*c*r)**-1))**-1 dxdt = vx dydt = vy dzdt = vz dvxdt = (x/r)*A*B*C dvydt = (y/r)*A*B*C dvzdt = (z/r)*A*B*C return [dxdt, dydt, dzdt, dvxdt, dvydt, dvzdt] t_span = (0.0, 40.0) t = np.arange(0.0, 40.0, 0.001) y0=[0, 1.2, 0, 0, -0.4, .1] ## initial state of the system y0=[x, y, z, vx, vy, vz] result = odeint(weber, y0, t, tfirst=True) Energy=T(y0[3], y0[4], y0[5] ) + U(y0[0],y0[1],y0[2],y0[3],y0[4],y0[5]) print(&#39;The initial total energy T+U is equal to:&#39;, Energy) print(&#39;The luminal energy is:&#39;, m*c*c/2) print(&#39;The energy is subliminal:&#39;, Energy &lt; m*c**2 /2) r=(y0[0]*y0[0] + y0[1]*y0[1] + y0[2]*y0[2])**0.5 print(&#39;Webers critical radius is equal to:&#39;,(m*c*c)**-1) print(&#39;The initial radius r is within the Weber critical distance:&#39;, r &lt; (m*c*c)**-1 ) fig = plt.figure() ax = fig.add_subplot(1, 2, 1, projection=&#39;3d&#39;) ax.plot(result[:, 0], result[:, 1], result[:, 2]) ax.set_title(&quot;position&quot;) ax = fig.add_subplot(1, 2, 2, projection=&#39;3d&#39;) ax.plot(result[:, 3], result[:, 4], result[:, 5]) ax.set_title(&quot;velocity&quot;) . The initial total energy T+U is equal to: 0.8091666666666666 The luminal energy is: 0.25 The energy is subliminal: False Webers critical radius is equal to: 2.0 The initial radius r is within the Weber critical distance: True . Text(0.5, 0.92, &#39;velocity&#39;) . import matplotlib.pyplot import pylab def rho(x,y,z): return (x*x+y*y+z*z)**0.5 v_list=[] for j in range(4000): v_list.append( (rho(result[j,0], result[j,1], result[j,2]), T(result[j,3], result[j,4], result[j,5])) ) U_list=[] for j in range(4000): U_list.append( (rho(result[j,0], result[j,1], result[j,2]), U(result[j,0],result[j,1],result[j,2],result[j,3],result[j,4],result[j,5])+T(result[j,3], result[j,4], result[j,5])) ) prelist1 = list(zip(*v_list)) pylab.scatter(list(prelist1[0]),list(prelist1[1])) pylab.xlabel(&#39;distance r&#39;) pylab.ylabel(&#39;Kinetic Energy T&#39;) pylab.title(&#39;rT plot&#39;) pylab.show() prelist2 = list(zip(*U_list)) pylab.scatter(list(prelist2[0]),list(prelist2[1])) pylab.xlabel(&#39;distance r&#39;) pylab.ylabel(&#39;T+U&#39;) pylab.title(&#39;Conservation of Energy&#39;) pylab.show() ## Error. Expect to see conservation of energy T+U = constant in the second figure. However the sum T+U appears nonconstant. . Discussion: The horizontal axis is the radial distance $r$ from the origin, and the vertical axis is the energy value. We expect the second figure to be a horizontal straight line. It does appear basically flat except for blow-up behaviour at small distance. Perhaps given the relative size of the interval of integration, namely $0.001$, the total energy $T+U$ is constant within error. . Is this loss/gain of energy a defect from the odeint routine? In otherwords, is energy not conserved because of cumulative errors and approximations in the solution? . for j in range(50): print( U(result[j,0],result[j,1],result[j,2],result[j,3],result[j,4],result[j,5]) + T(result[j,3], result[j,4], result[j,5]) ) . 0.8091666666666666 0.8091694528769837 0.8091722560959542 0.8091750763849768 0.8091779137441633 0.8091807683256578 0.8091836401044897 0.8091865291060831 0.8091894353679061 0.8091923589396186 0.8091952998832174 0.8091982582731821 0.8092012341218966 0.8092042274175154 0.8092072382239642 0.8092102666157523 0.8092133126780814 0.8092163765069865 0.8092194582094769 0.8092225578481547 0.8092256753069924 0.8092288106302348 0.8092319638914872 0.8092351351750412 0.8092383245760144 0.8092415322004902 0.8092447570890509 0.8092480017730359 0.8092512645080137 0.8092545454217692 0.8092578446432682 0.8092611623026272 0.8092644985310876 0.8092678534609862 0.809271227118879 0.8092746194540041 0.8092780305448041 0.8092814604679077 0.8092849092969379 0.8092883771024215 0.8092918639517022 0.8092953699088504 0.8092988950345746 0.80930243938613 0.8093060030172264 0.8093095859779383 0.8093131883146094 0.8093168100697619 0.8093204512819989 0.8093241120128701 . Radius of Weber&#39;s Planetary Atomic Model . Now we consider the diameter of Weber&#39;s critical radius if the test particles $x_1$, $x_2$ are equal to a positron, electron pair. . The mass of the electron is: [ref]. . Lagrangian L=T-U . Given the conservation of energy $d(T+U)=0$ it seems natural to consider the so-called Lagrangian $L=T-U$. But what do we expect from this lagrangian? Is there any reason to believe that a &quot;minimum action&quot; principle holds for two-body systems? Does the above naive expression for $L$ actually correspond to a reasonable action functional on the state space? . L_list=[] for j in range(4000): L_list.append( (rho(result[j,0], result[j,1], result[j,2]), -U(result[j,0],result[j,1],result[j,2],result[j,3],result[j,4],result[j,5])+T(result[j,3], result[j,4], result[j,5])) ) prelist2 = list(zip(*L_list)) pylab.scatter(list(prelist2[0]),list(prelist2[1])) pylab.show() .",
            "url": "https://jhmartel.github.io/fp/fastpages/jupyter/2022/02/10/LetterToAssisWeberPotentials.html",
            "relUrl": "/fastpages/jupyter/2022/02/10/LetterToAssisWeberPotentials.html",
            "date": " • Feb 10, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "Title",
            "content": "!pip install curver ## need install curver package. . import curver ## we load the mapping class group of genus two with one puncture ## S=curver.load(2,1) ## Below are the standard generators in Lickorish presentation, following Bell, Margalit, etc.. ## Id=S(&#39;&#39;) a=S(&#39;a_0&#39;) A=a**-1 b=S(&#39;a_1&#39;) B=b**-1 c=S(&#39;c_0&#39;) C=c**-1 d=S(&#39;d_1&#39;) D=d**-1 e=S(&#39;b_0&#39;) E=e**-1 f=S(&#39;b_1&#39;) F=f**-1 ## Ad is the adjoint action ## which replaces w2 by the w1-conjugate. def Ad(w1, w2): return w1*w2*(w1**-1) ## Translate is used to compute the adjoint action ## on a collection of curves, i.e. the pants p. def Translate(x, p): return {Ad(x,w) for w in p} ## br stands for &quot;bracket&quot; like &quot;commutator bracket&quot;. ## Thus br(x,y)=[x,y]=xyx^{-1} y^{1} in the usual group-theoretic notation def br(x,y): return Ad(x,y)*(y**-1) pant={a,b,c} zeta=a*e*c*f*b ## zeta is the order 6 element in MCG arising from chain relation. ## nu=a*e*c*f ## nu is order 10 element in MCG mu=nu**4 ## mu is order 5 element in MCG. ## The following code shows that pant and mu.pant are &quot;dual&quot; pants. #for x in pant: # for y in Translate(mu, pant): # if br(x,y)==Id: # print(&quot;The elements commute! And the curves are disjoint!&quot; ) # if br(x,y)!=Id: # print(&quot;The elements are NONcommuting. Now evaluating dual relation:&quot;, x*y*x==y*x*y) # else: pass ## xi is the steinberg symbol in our case. ## xi is obtained by joining the initial pant p with its mu translate. xi=pant|Translate(mu, pant) ## We need verify that the mu-translate of p is &quot;dual&quot; to p ## in the appropriate intersection-theoretic sense. This duality ## is nonstandard definition. #print(xi) ## important to verify that pant and the mu-translate are disjoint. ## Ad(mu,pant) is &quot;opposite pair of pants&quot; print(&quot;The mu translate of the standard pant is disjoint from pant. &quot;, pant &amp; Translate(mu, pant) == set()) print() ## Now translate the symbol xi by the powers of mu. ## The translates are not disjoint, good!, that means there is cancellation in the symmetric difference. print(&quot;The Steinberg symbol in our calculation is xi, and is the sum of the standard pant with its mu translate.&quot;) print() M0=xi M1=Translate(mu,xi) M2=Translate(mu**2,xi) M3=Translate(mu**3,xi) M4=Translate(mu**4,xi) ## The following proves that all the symbol translates are nontrivial, and there is no complete coincidence ## between the translated symbols. print(&quot;The mu translates of xi are all pairwise distinct:&quot;, M0!=M1 and M0!=M2 and M0!=M3 and M0!=M4 and M1!=M2 and M1!=M3 and M1!=M4 and M2!=M3 and M2!=M4 and M3!=M4 ) print() ## The following proves that the total chain sum of the translated symbols vanishes mod 2. ## I.e. the iterated symmetric difference of the translated symbols is equal to empty set. print(&quot;The iterated symmetric difference of the mu translates is empty.&quot;, ((((M0^M1))^M2)^M3)^M4 ==set()) print() print(&quot;The mu-orbit of xi is supported on ten curves.&quot;, 10==len(M0|M1|M2|M3|M4) ) print() print(&quot;Therefore we find I={Id, mu, mu**2, mu**3, mu**4} is a formal solution to Closing the Steinberg symbol xi in genus two.&quot;) print(&quot;&quot;) . The mu translate of the standard pant is disjoint from pant. True The Steinberg symbol in our calculation is xi, and is the sum of the standard pant with its mu translate. The mu translates of xi are all pairwise distinct: True The iterated symmetric difference of the mu translates is empty. True The mu-orbit of xi is supported on ten curves. True Therefore we find I={Id, mu, mu**2, mu**3, mu**4} is a formal solution to Closing the Steinberg symbol xi in genus two. . B0=M0|M1|M2|M3|M4 gen=(Id, a, A, b, B, c, C, d, D, e, E, f, F) gen1=(x*y for x in gen for y in gen) sample1=set(gen)|set(gen1) gen2=(x*y for x in gen for y in sample1) sample2=sample1|set(gen2) # gen3=(x*y for x in gen for y in gen2) #len(set(gen3)) len(sample2) #for word in gen1: # print( len(Translate(word, B0) &amp; B0)) . 105 . )B**-1 .",
            "url": "https://jhmartel.github.io/fp/2022/02/08/ClosingSteinbergGenusTwo.html",
            "relUrl": "/2022/02/08/ClosingSteinbergGenusTwo.html",
            "date": " • Feb 8, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jhmartel.github.io/fp/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Welcome to JHM Labs. . JHM is a Canadian mathematician, specializing in optimal transport, costs, probability, energy, electrodynamics, topology of singularities, and more. Beyond mathematics, we have interest in natural science, classical physics, economics, monetary policy, commodities, and technology. . This website is powered by fastpages 1. We are releasing preprints and broadcasting ideas and short articles. Our goal is to regularly release draft articles. Specifically we are interested in developing our python skills, investigating the electrodynamics inspired by Ampere, Weber, and the Brazilian physicist A.K.T. Assis at Unicamp University. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jhmartel.github.io/fp/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jhmartel.github.io/fp/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}